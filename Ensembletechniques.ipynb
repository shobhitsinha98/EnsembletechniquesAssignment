{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0582269-8a30-4d17-aac0-11673692160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Shobhit-Sinha\n",
    "Theoretical\n",
    "\n",
    "1. Can we use Bagging for regression problems?\n",
    "\n",
    "Why Bagging Works for Regression:\n",
    "\n",
    "1. Reduces Variance: Bagging, which stands for Bootstrap Aggregating, primarily aims to reduce variance in a model. In regression, high variance means\n",
    "the model's predictions can vary significantly depending on the training data it's given. This can lead to overfitting, where the model performs well\n",
    "on the training data but poorly on unseen data. Bagging helps mitigate this by averaging predictions from multiple models trained on different subsets\n",
    "of the data, thus stabilizing the predictions and reducing overfitting.\n",
    "\n",
    "2. Improves Accuracy: By combining predictions from multiple models (an ensemble), bagging often leads to improved accuracy compared to using a single\n",
    "   model. This is because the ensemble can capture a wider range of patterns in the data and make more robust predictions.\n",
    "\n",
    "How Bagging Works for Regression:\n",
    "\n",
    "1. Bootstrapping: The process starts by creating multiple bootstrap samples from the original training data. Each bootstrap sample is a random subset \n",
    "   of the original data, drawn with replacement (meaning some data points may appear multiple times in a single sample).\n",
    "\n",
    "2. Model Training: A base regression model (e.g., a decision tree, linear regression) is trained on each bootstrap sample independently. This results\n",
    "   in multiple models, each with a slightly different perspective on the data.\n",
    "\n",
    "3. Aggregation: When making predictions on new data, each model in the ensemble generates a prediction. These individual predictions are then aggregated\n",
    "   to produce the final prediction. For regression problems, the aggregation is typically done by averaging the predictions.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda2016c-55fc-4a9d-bee6-27ed37f452b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. What is the difference between multiple model training and single model training?\n",
    "\n",
    "Single Model Training\n",
    "\n",
    ". Concept: In single model training, you train one model on your entire dataset. You aim to find the best possible parameters for this single model to \n",
    "  make accurate predictions.\n",
    ". Advantages:\n",
    "     . Simplicity: It's straightforward to implement and understand.\n",
    "     . Efficiency: It's generally faster as you're training only one model.\n",
    ". Disadvantages:\n",
    "      . Risk of Overfitting: The model might become too specialized to the training data and not generalize well to unseen data.\n",
    "      . Limited Perspective: A single model might not capture all the complex patterns in the data.\n",
    "\n",
    ". Multiple Model Training\n",
    "\n",
    ". Concept: This involves training several models, either of the same type with different hyperparameters or different types altogether. The predictions\n",
    "  from these multiple models are then combined to produce a final prediction. This is also known as ensemble learning.\n",
    "Advantages:\n",
    ". Improved Accuracy: Combining predictions from multiple models often leads to better overall accuracy and generalization.\n",
    ". Robustness: Ensembles are less prone to overfitting as they leverage the strengths of different models.\n",
    ". Handling Complex Data: Multiple models can capture different aspects of complex datasets.\n",
    "\n",
    "Disadvantages:\n",
    "   . Complexity: More complex to implement and manage compared to single model training.\n",
    "   . Computational Cost: Training multiple models requires more computational resources and time.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1de75d5-72aa-454f-ab56-8ec3d70ba4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3. Explain the concept of feature randomness in Random Forest.\n",
    "\n",
    "Feature Randomness (or Feature Bagging)\n",
    "\n",
    "In a Random Forest, feature randomness is a crucial technique used to introduce diversity and improve the model's performance. Here's how it works:\n",
    "\n",
    "1. Subset of Features: At each node of a decision tree within the Random Forest, only a random subset of features is considered for splitting the data.\n",
    "   This subset is typically much smaller than the total number of features available.\n",
    "\n",
    "2. Random Selection: The features for the subset are selected randomly from the total feature set.\n",
    "\n",
    "3. Splitting: The best split point is determined based on the selected subset of features. This ensures that different trees within the forest focus on\n",
    "  different aspects of the data.\n",
    "\n",
    "Benefits of Feature Randomness:\n",
    "\n",
    "1. Reduced Correlation: By considering only a subset of features at each node, feature randomness helps to decorrelate the trees in the forest. This is\n",
    "  important because highly correlated trees tend to make similar errors, reducing the overall performance of the ensemble.\n",
    "\n",
    "2. Increased Diversity: Feature randomness introduces diversity in the trees by forcing them to consider different features for splitting. This\n",
    "   diversity helps the forest capture a wider range of patterns in the data.\n",
    "\n",
    "3. Improved Generalization: The combination of reduced correlation and increased diversity leads to better generalization, meaning the model is less\n",
    "   likely to overfit the training data and is more likely to perform well on unseen data.\n",
    "\n",
    "Analogy:\n",
    "\n",
    "Imagine you have a group of detectives trying to solve a crime. If all the detectives focus on the same clues, they might miss important details. \n",
    "However, if each detective investigates a different set of clues, they are more likely to uncover the truth. Feature randomness in Random Forest is\n",
    "similar to assigning different clues to different detectives, leading to a more comprehensive investigation of the data.\n",
    "\n",
    "In essence, feature randomness helps to create a more robust and accurate Random Forest model by:\n",
    "\n",
    ". Preventing individual trees from becoming too dominant.\n",
    ". Encouraging exploration of different feature combinations.\n",
    ". Reducing the risk of overfitting.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852be366-0a34-4a75-9c2c-3864109bc3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "4. What is OOB (Out-of-Bag) Score?\n",
    "OOB Score\n",
    "\n",
    "The OOB score is a way to evaluate the performance of a Random Forest model without needing a separate validation dataset. It's like having a built-in\n",
    "cross-validation mechanism. Here's how it works:\n",
    "\n",
    "1. Bootstrapping: When building a Random Forest, each decision tree is trained on a bootstrap sample, which is a random subset of the original training\n",
    "   data drawn with replacement.\n",
    "\n",
    "2. Out-of-Bag Samples: On average, about one-third of the training data is not included in each bootstrap sample. These data points are called \\\n",
    "   \"out-of-bag\" (OOB) samples for that particular tree.\n",
    "\n",
    "3. OOB Predictions: For each data point in the training set, predictions are made by the trees that did not use that data point in their training\n",
    "  (i.e., the trees for which that data point is an OOB sample).\n",
    "\n",
    "4. OOB Score Calculation: The OOB score is then calculated by aggregating the predictions for all data points and comparing them to the true values.\n",
    "  This can be done using metrics like accuracy (for classification) or R-squared (for regression).\n",
    "\n",
    "Benefits of OOB Score:\n",
    "\n",
    ". No Need for Validation Set: You don't have to split your data into training and validation sets, saving you valuable data for training.\n",
    ". Efficient Evaluation: OOB score is calculated during the training process itself, making it efficient.\n",
    ". Good Estimate of Performance: The OOB score is often a good estimate of the model's performance on unseen data, similar to what you would get from\n",
    "  cross-validation.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa4aac-cfd1-430a-9898-04874d5bcbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "5. How can you measure the importance of features in a Random Forest model?\n",
    "Feature Importance in Random Forest\n",
    "\n",
    "Random Forests offer a built-in mechanism to assess the importance of features in making predictions. This is based on the idea that features used for\n",
    "crucial splits in the decision trees contribute more to the model's predictive power.\n",
    "\n",
    "Here are the main methods for measuring feature importance:\n",
    "1. Gini Importance (or Mean Decrease Impurity):\n",
    "\n",
    "   . This method calculates the total reduction in the Gini impurity (a measure of node impurity) achieved by a feature across all trees in the forest.\n",
    "   . Features that lead to larger decreases in impurity are considered more important.\n",
    "   . It's the default feature importance measure in scikit-learn's RandomForestClassifier and RandomForestRegressor.\n",
    "\n",
    "2. Permutation Importance (or Mean Decrease Accuracy):\n",
    "\n",
    ". This method involves randomly shuffling the values of a single feature in the out-of-bag (OOB) samples and measuring the decrease in the model's\n",
    "  accuracy.\n",
    ". A larger decrease in accuracy indicates that the feature is more important.\n",
    ". Permutation importance is often considered more reliable than Gini importance, especially when dealing with high cardinality categorical features or\n",
    "  correlated features.\n",
    "\n",
    "Visualizing Feature Importance:\n",
    "\n",
    "You can use libraries like matplotlib or seaborn to create visualizations of feature importances, such as bar plots or heatmaps, to better understand\n",
    "the relative importance of different features.\n",
    "\n",
    "Interpreting Feature Importance:\n",
    ". Higher values indicate more important features.\n",
    ". Feature importance scores are relative to each other, not absolute measures.\n",
    ". You can use feature importance to:\n",
    "       . Feature selection: Identify and select the most important features for your model.\n",
    "       . Gain insights: Understand which features are driving the predictions of your model.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eb75b1-e2c2-41cf-9789-a20af9472273",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "6. Explain the working principle of a Bagging Classifier.\n",
    "Bagging Classifier: Bootstrap Aggregating for Classification\n",
    "\n",
    "Bagging, short for Bootstrap Aggregating, is an ensemble learning technique that aims to improve the accuracy and stability of classification models. \n",
    "Here's how a Bagging Classifier works:\n",
    "1. Bootstrapping:\n",
    "\n",
    " . The process starts by creating multiple bootstrap samples from the original training data.\n",
    " . Each bootstrap sample is a random subset of the data, drawn with replacement (meaning some data points may appear multiple times in a single sample).\n",
    " . Typically, the size of each bootstrap sample is the same as the original training set.\n",
    "\n",
    "2. Parallel Training:\n",
    "\n",
    ". A base classifier (e.g., a decision tree, k-nearest neighbors) is trained independently on each bootstrap sample.\n",
    ". This results in multiple classifiers, each with a slightly different perspective on the data due to the variations in the bootstrap samples.\n",
    "\n",
    "3. Aggregation (Voting):\n",
    "\n",
    ". When making predictions on new data, each classifier in the ensemble makes a prediction.\n",
    ". These individual predictions are then aggregated to produce the final prediction.\n",
    ". For classification, the aggregation is usually done by majority voting: the class predicted by the majority of classifiers becomes the final\n",
    "  prediction.\n",
    "\n",
    "Key Principles and Benefits:\n",
    "\n",
    ". Reduces Variance: Bagging primarily aims to reduce variance in a model, which is the sensitivity of the model to fluctuations in the training data.\n",
    "  By averaging predictions from multiple models trained on different subsets of the data, bagging stabilizes the predictions and reduces overfitting.\n",
    "\n",
    ". Improves Accuracy: By combining predictions from multiple classifiers, bagging often leads to improved accuracy compared to using a single classifier.\n",
    "  This is because the ensemble can capture a wider range of patterns in the data and make more robust predictions.\n",
    "\n",
    ". Robust to Noise and Outliers: Bagging is relatively robust to noisy data and outliers, as the individual classifiers are less likely to be heavily \n",
    "  influenced by them due to the random sampling in bootstrapping.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebac23f-3fe5-4d73-a30e-ac2a748135ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "7. How do you evaluate a Bagging Classifier's performance?\n",
    "Evaluating a Bagging Classifier\n",
    "\n",
    "Evaluating a Bagging Classifier involves assessing its ability to accurately classify data points. Here are the key steps and metrics used for \n",
    "evaluation:\n",
    "\n",
    "1. Splitting Data:\n",
    "\n",
    ". Divide your dataset into training and testing sets.\n",
    ". The training set is used to train the Bagging Classifier.\n",
    ". The testing set is used to evaluate the performance of the trained model on unseen data.\n",
    "\n",
    "2. Making Predictions:\n",
    "\n",
    ". Use the trained Bagging Classifier to make predictions on the testing set.\n",
    ". This will give you predicted class labels for each data point in the testing set.\n",
    "\n",
    "3. Comparing Predictions to True Labels:\n",
    "\n",
    ". Compare the predicted class labels to the true class labels of the testing set.\n",
    ". This comparison forms the basis for calculating various evaluation metrics.\n",
    "\n",
    "Evaluation Metrics:\n",
    "\n",
    "Here are some common metrics used to evaluate the performance of a Bagging Classifier:\n",
    "\n",
    ". Accuracy: The proportion of correctly classified instances out of the total instances in the testing set.\n",
    ". Precision: The proportion of correctly classified positive instances out of all instances predicted as positive.\n",
    ". Recall (Sensitivity): The proportion of correctly classified positive instances out of all actual positive instances.\n",
    ". F1-Score: The harmonic mean of precision and recall, providing a balanced measure of performance.\n",
    ". ROC AUC (Area Under the Receiver Operating Characteristic Curve): A measure of the classifier's ability to distinguish between classes across \n",
    "  different classification thresholds.\n",
    ". Confusion Matrix: A table that shows the counts of true positive, true negative, false positive, and false negative predictions, providing a detailed \n",
    "  breakdown of the classifier's performance.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c8b53b-82b0-4fd1-99c7-242293e21abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "8. How does a Bagging Regressor work?\n",
    "\n",
    "Bagging Regressor: Bootstrap Aggregating for Regression\n",
    "\n",
    "Bagging, which stands for Bootstrap Aggregating, is an ensemble learning technique that can be applied to regression problems as well. A Bagging \n",
    "Regressor works by combining predictions from multiple base regressors trained on different subsets of the data to improve prediction accuracy and \n",
    "stability.\n",
    "\n",
    "Here's a breakdown of the process:\n",
    "\n",
    "1. Bootstrapping:\n",
    "\n",
    "   . Similar to Bagging Classifiers, the process begins by creating multiple bootstrap samples from the original training data.\n",
    "   . Each bootstrap sample is a random subset of the data, drawn with replacement.\n",
    "   . The size of each bootstrap sample is typically the same as the original training set.\n",
    "2. Parallel Training:\n",
    "\n",
    "  . A base regressor (e.g., a decision tree, linear regression) is trained independently on each bootstrap sample.\n",
    "  . This results in multiple regressors, each with a slightly different perspective on the data due to the variations in the bootstrap samples.\n",
    "\n",
    "3. Aggregation (Averaging):\n",
    "\n",
    " . When making predictions on new data, each regressor in the ensemble generates a prediction.\n",
    " . These individual predictions are then aggregated to produce the final prediction.\n",
    " . For regression problems, the aggregation is typically done by averaging the predictions from all the base regressors.\n",
    "\n",
    "Key Principles and Benefits:\n",
    "\n",
    ". Reduces Variance: Bagging primarily aims to reduce variance in a regression model, which is the sensitivity of the model to fluctuations in the \n",
    "  training data. By averaging predictions from multiple models trained on different subsets of the data, bagging stabilizes the predictions and reduces\n",
    "  overfitting.\n",
    "\n",
    ". Improves Accuracy: By combining predictions from multiple regressors, bagging often leads to improved accuracy compared to using a single regressor.\n",
    "  This is because the ensemble can capture a wider range of patterns in the data and make more robust predictions.\n",
    "\n",
    ". Robust to Noise and Outliers: Bagging is relatively robust to noisy data and outliers, as the individual regressors are less likely to be heavily \n",
    "  influenced by them due to the random sampling in bootstrapping.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71679ca9-e230-45e0-aa4e-681f456f5616",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "9. What is the main advantage of ensemble techniques?\n",
    "Main Advantage: Improved Predictive Performance\n",
    "\n",
    "The primary advantage of ensemble techniques is their ability to significantly improve predictive performance compared to using a single model. This\n",
    "improvement is achieved through the combination of multiple models, which leads to:\n",
    "\n",
    "1. Reduced Variance: Ensembles reduce variance, which is the sensitivity of a model to fluctuations in the training data. By averaging or combining \n",
    "   predictions from multiple models trained on different subsets of the data, ensembles stabilize the predictions and reduce overfitting. This is \n",
    "   especially beneficial when dealing with complex or noisy datasets.\n",
    "\n",
    "2. Improved Accuracy: Ensembles often lead to improved accuracy compared to using a single model. This is because the ensemble can capture a wider range\n",
    "   of patterns in the data and make more robust predictions. By leveraging the strengths of different models, ensembles can achieve higher accuracy and\n",
    "   better generalization to unseen data.\n",
    "\n",
    "3. Increased Robustness: Ensembles are more robust to noise and outliers compared to single models. Individual models in the ensemble may be affected by\n",
    "   noise or outliers, but the combined prediction is less likely to be heavily influenced by them. This makes ensembles more reliable in real-world \n",
    "   scenarios where data may be imperfect.\n",
    "\n",
    "Analogy:\n",
    "\n",
    "Imagine you're trying to make an important decision. Instead of relying on the opinion of a single person, you might consult multiple experts with \n",
    "different perspectives and expertise. By considering their diverse opinions and combining their insights, you're likely to make a more informed and\n",
    "accurate decision. Ensemble techniques work in a similar way, leveraging the strengths of multiple models to improve predictive performance.\n",
    "\n",
    "In essence:\n",
    "\n",
    "Ensemble techniques offer a powerful way to enhance the performance of machine learning models by combining the predictions of multiple models. This\n",
    "leads to reduced variance, improved accuracy, and increased robustness, making ensembles a valuable tool for a wide range of applications.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d04d1d9-46d9-4ee2-a374-e71057416cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "10. What is the main challenge of ensemble methods?\n",
    "\n",
    "Main Challenge: Increased Complexity and Computational Cost\n",
    "\n",
    "While ensemble methods offer significant advantages in terms of predictive performance, their main challenge lies in their increased complexity and \n",
    "computational cost compared to using a single model. This challenge manifests in several ways:\n",
    "\n",
    "1. Computational Resources: Training multiple models requires more computational resources and time than training a single model. This can be a \n",
    "  significant factor, especially when dealing with large datasets or complex models.\n",
    "\n",
    "2. Memory Usage: Ensembles require more memory to store the multiple models and their parameters. This can be a constraint in environments with limited\n",
    "   memory resources.\n",
    "\n",
    "3. Interpretability: Ensembles can be more difficult to interpret than single models. Understanding how the individual models contribute to the final\n",
    "   prediction can be challenging, especially with complex ensembles.\n",
    "\n",
    "4. Model Selection and Tuning: Choosing the right base models, ensemble technique, and hyperparameters can be a complex task. It often involves \n",
    "   experimentation and careful tuning to optimize the performance of the ensemble.\n",
    "\n",
    "5. Potential Overfitting: While ensembles generally reduce overfitting, there is still a risk of overfitting if the ensemble is too complex or if the \n",
    "   base models are highly correlated.\n",
    "\n",
    "Mitigating the Challenge:\n",
    "\n",
    "While the complexity and computational cost of ensemble methods are inherent, there are ways to mitigate these challenges:\n",
    "\n",
    ". Careful Model Selection: Choose base models that are diverse and have complementary strengths.\n",
    ". Feature Selection: Reduce the number of features used in the models to decrease complexity.\n",
    ". Hyperparameter Tuning: Optimize the hyperparameters of the ensemble and base models to improve performance.\n",
    ". Parallel Computing: Utilize parallel computing techniques to speed up the training process.\n",
    ". Model Compression: Explore techniques to compress the size of the ensemble to reduce memory usage.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c05df-107e-40ae-afdd-30e1e4fd50bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "11. Explain the key idea behind ensemble techniques.\n",
    "Ensemble techniques in machine learning combine predictions from multiple models (often called \"base learners\" or \"weak learners\") to improve overall \n",
    "prediction accuracy.\n",
    "\n",
    "Key Idea:\n",
    "\n",
    "The core principle is that by combining the strengths of different models, the ensemble can achieve better performance than any individual model could \n",
    "on its own.\n",
    "\n",
    "Analogy:\n",
    "Think of it like seeking advice from multiple experts before making a big decision. Each expert has their own perspective and expertise, and by \n",
    "considering their diverse opinions, you're likely to make a more informed choice.\n",
    "\n",
    "Reasoning:\n",
    "\n",
    ". Reduces Variance: By averaging predictions from multiple models, ensemble methods can reduce the variance in the predictions, making them more stable\n",
    "  and less prone to overfitting.\n",
    ". Reduces Bias: Different models may have different biases. Combining them can help to cancel out these biases and improve the overall accuracy.\n",
    ". Improves Robustness: Ensembles are less sensitive to outliers and noisy data points compared to individual models.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685171c4-bdab-4241-a25c-d911d8add3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "12. What is a Random Forest Classifier?\n",
    "A Random Forest Classifier is a popular ensemble learning method used for classification tasks. It belongs to the bagging (Bootstrap Aggregating) \n",
    "family of ensemble techniques.\n",
    "\n",
    "Key Idea:\n",
    "\n",
    "A Random Forest builds multiple decision trees and combines their predictions to make a final classification.\n",
    "Steps:\n",
    "\n",
    ". Bootstrap Sampling: It creates multiple subsets of the training data by randomly sampling with replacement (bootstrap sampling). Each subset is used\n",
    "  to train a different decision tree.\n",
    ". Feature Randomness: When building each tree, only a random subset of features is considered at each split point. This introduces diversity among the\n",
    "  trees.\n",
    ". Building Decision Trees: Each tree is grown to its full depth without pruning.\n",
    ". Aggregation: For a classification task, the predictions from all trees are combined using majority voting. The class that receives the most votes\n",
    "  becomes the final prediction of the Random Forest.\n",
    "\n",
    "Reasoning:\n",
    "\n",
    ". Reduces Overfitting: By averaging predictions from multiple trees, Random Forest reduces the risk of overfitting to the training data.\n",
    ". Handles High Dimensionality: It can effectively handle datasets with many features due to the feature randomness step.\n",
    ". Robust to Noise: It is relatively robust to noisy data and outliers.\n",
    ". Provides Feature Importance: Random Forest can provide insights into the importance of different features in the classification task.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d567e3c2-9a65-4f2d-9f81-60dbe8b133ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "13. What are the main types of ensemble techniques?\n",
    "1. Bagging (Bootstrap Aggregating)\n",
    "\n",
    ". Key Idea: Create multiple subsets of the training data by randomly sampling with replacement (bootstrapping). Train a separate model on each subset \n",
    "  and\n",
    "  combine their predictions.\n",
    ". Example: Random Forest is a popular bagging algorithm where multiple decision trees are trained on bootstrapped samples.\n",
    ". Benefits: Reduces variance and overfitting, improves stability.\n",
    "\n",
    "2. Boosting\n",
    "\n",
    ". Key Idea: Sequentially train models, where each subsequent model focuses on correcting the errors made by the previous models.\n",
    ". Example: AdaBoost, Gradient Boosting, XGBoost are popular boosting algorithms.\n",
    ". Benefits: Improves accuracy, reduces bias, can handle complex relationships.\n",
    "\n",
    "3. Stacking\n",
    "\n",
    ". Key Idea: Train multiple diverse models (base learners) and then use another model (meta-learner) to combine their predictions.\n",
    ". Example: A stacking ensemble could use logistic regression, support vector machines, and decision trees as base learners, and a neural network as the\n",
    "  meta-learner.\n",
    ". Benefits: Can leverage the strengths of different models, potentially achieving higher accuracy than individual models or bagging/boosting.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac16b0a3-c6bb-4374-a3b7-3c47a5d4d4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "14. What is ensemble learning in machine learning?\n",
    "\n",
    "Ensemble learning is a machine learning technique that combines the predictions from multiple models (often referred to as \"base learners\" or \"weak\n",
    "learners\") to improve overall prediction accuracy.\n",
    "\n",
    "Key Idea:\n",
    "\n",
    "The core principle is that by combining the strengths of different models, the ensemble can achieve better performance than any individual model could\n",
    "on its own.\n",
    "\n",
    "Analogy:\n",
    "\n",
    "Think of it like seeking advice from multiple experts before making a big decision. Each expert has their own perspective and expertise, and by \n",
    "considering their diverse opinions, you're likely to make a more informed choice.\n",
    "Reasoning:\n",
    "\n",
    ". Reduces Variance: By averaging predictions from multiple models, ensemble methods can reduce the variance in the predictions, making them more stable\n",
    "  and less prone to overfitting.\n",
    ". Reduces Bias: Different models may have different biases. Combining them can help to cancel out these biases and improve the overall accuracy.\n",
    ". Improves Robustness: Ensembles are less sensitive to outliers and noisy data points compared to individual models.\n",
    "\n",
    "Benefits:\n",
    "\n",
    ". Increased Accuracy: Ensembles generally achieve higher accuracy compared to individual models.\n",
    ". Improved Stability: Ensembles are more stable and less prone to overfitting, leading to more reliable predictions.\n",
    ". Increased Robustness: Ensembles are less sensitive to outliers and noisy data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c77d2f-6707-4ea2-8d9e-ea67a29feef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "15. When should we avoid using ensemble methods?\n",
    "While ensemble methods are powerful and often lead to improved performance, there are certain situations where they might not be the best choice:\n",
    "\n",
    "1. Limited Resources:\n",
    "\n",
    ". Computational Cost: Training and deploying multiple models can be computationally expensive, especially for complex ensembles. If you have limited \n",
    "  computational resources or strict time constraints, using a single, well-tuned model might be more practical.\n",
    ". Memory Footprint: Ensembles require storing multiple models, which can lead to a larger memory footprint. This can be a concern if you have limited\n",
    "  memory resources or are deploying models on devices with limited storage.\n",
    "\n",
    "2. Simplicity and Interpretability:\n",
    "\n",
    ". Increased Complexity: Ensembles are inherently more complex than individual models, making them harder to interpret and debug. If interpretability is\n",
    "  a crucial requirement for your application, using a simpler model might be preferred.\n",
    ". Black Box Nature: Some ensemble methods, like deep stacking, can be considered \"black boxes,\" making it difficult to understand how they arrive at \n",
    "  their predictions.\n",
    "\n",
    "3. Small Datasets:\n",
    "\n",
    ". Potential Overfitting: While ensembles generally reduce overfitting, they can still be susceptible to it if the training dataset is very small. In \n",
    "  such cases, using a simpler model with appropriate regularization techniques might be more effective.\n",
    "\n",
    "4. Diminishing Returns:\n",
    "\n",
    ". Plateau in Performance: After a certain point, adding more models to the ensemble might not lead to significant improvements in performance. If you\n",
    "  observe diminishing returns, it might be better to focus on optimizing the existing models or exploring alternative approaches.\n",
    "\n",
    "5. Real-time Applications:\n",
    "\n",
    ". Latency Concerns: Ensembles can introduce latency in real-time applications due to the need to make predictions from multiple models. If low latency\n",
    "  is critical, using a single, fast model might be more appropriate.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14811d7a-63f5-4100-b8f5-01d88936e1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "16. How does Bagging help in reducing overfitting?\n",
    "\n",
    "Bagging reduces overfitting by creating multiple subsets of the original dataset and training a separate model on each subset. These subsets are created\n",
    "by randomly sampling data points from the original dataset with replacement (meaning the same data point can be selected multiple times).\n",
    "\n",
    "Here's a breakdown of how it works and why it helps:\n",
    "\n",
    "1. Creating Diverse Models: By training models on different subsets of data, Bagging creates a collection of models that are diverse in their\n",
    "   predictions. Each model learns slightly different patterns from the data it's trained on.\n",
    "\n",
    "2. Reducing Variance: When these diverse models are combined (usually by averaging their predictions), the overall variance of the final prediction is\n",
    "   reduced. This is because the errors of individual models tend to cancel each other out. High variance is a characteristic of overfitting, where the\n",
    "   model is too sensitive to the training data and performs poorly on unseen data.\n",
    "\n",
    "3. Improving Generalization: By reducing variance, Bagging helps the model generalize better to new, unseen data. The model becomes less likely to be\n",
    "   influenced by noise or outliers in the training data and more likely to capture the underlying patterns of the data.\n",
    "\n",
    "In simpler terms: Imagine you have a group of experts with different opinions. By combining their opinions, you are likely to get a more accurate and\n",
    "well-rounded prediction than by relying on a single expert. Bagging works in a similar way by combining the predictions of multiple models to reduce\n",
    "overfitting and improve the overall performance.\n",
    "\n",
    "Example: Random Forest is a popular machine learning algorithm that utilizes Bagging. It creates multiple decision trees and combines their predictions\n",
    "to make a final prediction. This ensemble approach helps to reduce overfitting and improve the accuracy of the model.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ebfd51-16ec-48b5-967a-e6a7702309e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "17. Why is Random Forest better than a single Decision Tree?\n",
    "Random Forest\n",
    "\n",
    ". Reduces Overfitting: Random Forest builds multiple decision trees (an ensemble) and combines their predictions. Each tree is trained on a different\n",
    "  subset of the data and features. This randomness helps to reduce overfitting, which is a common problem with single decision trees that can become\n",
    "  too complex and memorize the training data.\n",
    "  \n",
    ". Improved Accuracy: By combining predictions from multiple trees, Random Forest often achieves higher accuracy compared to a single decision tree. The\n",
    "  errors of individual trees tend to cancel out, leading to a more robust and accurate model.\n",
    "  \n",
    ". Handles High Dimensionality: Random Forest can handle datasets with a large number of features effectively. It randomly selects a subset of features\n",
    "  for each tree, which helps to reduce the impact of irrelevant or noisy features.\n",
    "  \n",
    ". Estimates Feature Importance: Random Forest can provide insights into the importance of different features in the dataset. It measures how much each\n",
    "  feature contributes to the overall accuracy of the model, which can be useful for feature selection and understanding the data.\n",
    "\n",
    "Decision Tree\n",
    "\n",
    ". Prone to Overfitting: Decision trees can easily overfit the training data, especially when they are deep and complex. This means they may perform well\n",
    "  on the training data but poorly on unseen data.\n",
    ". Less Robust: A single decision tree can be sensitive to small changes in the data. A slight variation in the training data can lead to a significantly\n",
    "  different tree structure and predictions.\n",
    ". Limited Accuracy: While decision trees can be accurate for some datasets, they often have lower accuracy compared to ensemble methods like Random\n",
    "  Forest, especially for complex datasets.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84306b71-dca9-4557-aed3-62321cbd27a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "18. What is the role of bootstrap sampling in Bagging?\n",
    "\n",
    "Bagging (Bootstrap Aggregating) is an ensemble method that aims to improve the accuracy and stability of machine learning models. It involves creating \n",
    "multiple subsets of the training data using bootstrap sampling and training a separate model on each subset. The predictions from these models are then\n",
    "combined to make the final prediction.\n",
    "\n",
    "Bootstrap Sampling is a resampling technique where we randomly draw data points from the original dataset with replacement to create a new dataset of \n",
    "the same size. This means that some data points may appear multiple times in the bootstrap sample, while others may not be included at all.\n",
    "\n",
    "Role of Bootstrap Sampling in Bagging\n",
    "\n",
    "1. Creating Diverse Subsets: Bootstrap sampling introduces diversity in the training data for each model in the ensemble. Since each bootstrap sample is\n",
    "different, the models trained on these samples will have slightly different perspectives on the data, leading to a more robust and accurate overall \n",
    "prediction.\n",
    "\n",
    "2. Reducing Variance: By training multiple models on different subsets of the data, bagging helps to reduce the variance of the final prediction. This\n",
    "   is because the errors of individual models tend to cancel out when their predictions are combined.\n",
    "\n",
    "3.Improving Generalization: Bagging helps the model to generalize better to unseen data by reducing overfitting. Since each model is trained on a \n",
    " slightly different dataset, it is less likely to memorize the training data and more likely to capture the underlying patterns in the data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c565e-5556-4e59-8dc3-8a73566a7fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "19. What are some real-world applications of ensemble techniques?\n",
    "\n",
    "Ensemble techniques are widely used across various domains due to their ability to improve prediction accuracy and model robustness. Here are some\n",
    "notable examples:\n",
    "\n",
    "1. Fraud Detection:\n",
    "\n",
    ". Ensemble methods like Random Forest and Gradient Boosting are employed to detect fraudulent transactions in financial institutions. By combining \n",
    "  multiple models, they can identify complex patterns and anomalies that indicate fraudulent activity.\n",
    "\n",
    "2. Medical Diagnosis:\n",
    "\n",
    ". Ensemble techniques are used to improve the accuracy of medical diagnoses, such as identifying diseases from medical images or predicting patient \n",
    "  outcomes. Combining different models can help to reduce diagnostic errors and provide more reliable predictions.\n",
    "\n",
    "3. Credit Risk Assessment:\n",
    "\n",
    ". Ensemble models are used by banks and financial institutions to assess the creditworthiness of loan applicants. By combining different models, they \n",
    "  can better predict the likelihood of loan defaults and make more informed lending decisions.\n",
    "  \n",
    "4. Remote Sensing and Image Recognition:\n",
    "\n",
    ". Ensemble techniques are applied in remote sensing for tasks like land cover classification and object detection. Combining multiple models can improve\n",
    "  the accuracy of image analysis and provide more detailed information about the environment.\n",
    "  \n",
    "5. Natural Language Processing:\n",
    "\n",
    ". Ensemble methods are used in various natural language processing tasks, such as sentiment analysis, text classification, and machine translation.\n",
    "  Combining different models can help to improve the accuracy and robustness of these systems.\n",
    "  \n",
    "6. Recommendation Systems:\n",
    "\n",
    ". Ensemble techniques are employed in recommendation systems to provide personalized recommendations to users. By combining different models, they can \n",
    "  better predict user preferences and offer more relevant recommendations.\n",
    "\n",
    "7. Weather Forecasting:\n",
    "\n",
    ". Ensemble methods are used in weather forecasting to improve the accuracy of predictions. By combining multiple models, they can better account for \n",
    "  the uncertainty and complexity of weather systems.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de89e2b-4b6c-4908-afa2-fb2e7a7ab2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "20. What is the difference between Bagging and Boosting?\n",
    "\n",
    "Both Bagging and Boosting are ensemble techniques that combine multiple models to improve prediction accuracy. However, they differ in how they create\n",
    "and combine these models.\n",
    "\n",
    "Bagging (Bootstrap Aggregating)\n",
    "\n",
    " 1. Model Creation: Bagging creates multiple subsets of the training data using bootstrap sampling (random sampling with replacement). A separate model\n",
    "    is trained on each subset independently. These models are typically of the same type, such as decision trees.\n",
    "\n",
    " 2. Model Combination: The predictions from individual models are combined using averaging (for regression) or voting (for classification) to make the\n",
    "    final prediction.\n",
    "\n",
    " 3. Focus: Bagging primarily aims to reduce variance and improve the stability of the model by reducing the impact of individual data points.\n",
    "\n",
    " 4. Example: Random Forest is a popular bagging algorithm that uses multiple decision trees trained on different subsets of the data.\n",
    "\n",
    "Boosting\n",
    "\n",
    " 1. Model Creation: Boosting trains models sequentially, where each subsequent model focuses on correcting the errors made by the previous model. The\n",
    "    models are typically weak learners, such as shallow decision trees.\n",
    "\n",
    " 2. Model Combination: The predictions from individual models are combined using weighted averaging, where models with better performance are given\n",
    "    higher weights.\n",
    "\n",
    " 3. Focus: Boosting primarily aims to reduce bias and improve the accuracy of the model by focusing on the data points that are difficult to predict.\n",
    "\n",
    " 4. Example: AdaBoost and Gradient Boosting are popular boosting algorithms that sequentially train weak learners to improve the overall model \n",
    "    performance.\n",
    "Here's a table summarizing the key differences:\n",
    "\n",
    "Feature  \t             Bagging\t                         Boosting\n",
    "Model Creation\t     Independent, parallel\t             Sequential, iterative\n",
    "Model Combination\t  Averaging/Voting\t                 Weighted Averaging\n",
    "Focus\t              Reduce variance\t                   Reduce bias\n",
    "Example\t               Random Forest\t              AdaBoost, Gradient Boosting\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70318d31-9f25-4b14-b432-0919e5a83840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Practical\n",
    "\n",
    "21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy.\n",
    "'''\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a Decision Tree classifier - Renamed to estimator\n",
    "estimator = DecisionTreeClassifier()  \n",
    "\n",
    "# Create a Bagging Classifier with 10 Decision Trees\n",
    "bagging_classifier = BaggingClassifier(estimator=estimator, n_estimators=10, random_state=42) \n",
    "\n",
    "# Train the Bagging Classifier\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = bagging_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4afcc89d-85c0-4633-b1b2-9bb08b39ae88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.2824242776841025\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE).\n",
    "'''\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import fetch_california_housing # Use California housing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the California Housing dataset\n",
    "california = fetch_california_housing()\n",
    "X, y = california.data, california.target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree Regressor as the base estimator\n",
    "estimator = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Create a Bagging Regressor with 10 Decision Trees\n",
    "bagging_regressor = BaggingRegressor(estimator=estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the Bagging Regressor\n",
    "bagging_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = bagging_regressor.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Print the MSE\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8db1d9b0-ca53-479d-a29f-53c6f656a3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Feature  Importance\n",
      "7       mean concave points    0.141934\n",
      "27     worst concave points    0.127136\n",
      "23               worst area    0.118217\n",
      "6            mean concavity    0.080557\n",
      "20             worst radius    0.077975\n",
      "22          worst perimeter    0.074292\n",
      "2            mean perimeter    0.060092\n",
      "3                 mean area    0.053810\n",
      "26          worst concavity    0.041080\n",
      "0               mean radius    0.032312\n",
      "13               area error    0.029538\n",
      "21            worst texture    0.018786\n",
      "25        worst compactness    0.017539\n",
      "10             radius error    0.016435\n",
      "28           worst symmetry    0.012929\n",
      "12          perimeter error    0.011770\n",
      "24         worst smoothness    0.011769\n",
      "1              mean texture    0.011064\n",
      "5          mean compactness    0.009216\n",
      "19  fractal dimension error    0.007135\n",
      "29  worst fractal dimension    0.006924\n",
      "4           mean smoothness    0.006223\n",
      "14         smoothness error    0.005881\n",
      "16          concavity error    0.005816\n",
      "15        compactness error    0.004596\n",
      "18           symmetry error    0.004001\n",
      "17     concave points error    0.003382\n",
      "8             mean symmetry    0.003278\n",
      "11            texture error    0.003172\n",
      "9    mean fractal dimension    0.003140\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores.\n",
    "'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "breast_cancer = load_breast_cancer()\n",
    "X, y = breast_cancer.data, breast_cancer.target\n",
    "feature_names = breast_cancer.feature_names\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf_classifier.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the feature importances\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8014df58-7fac-447d-8d03-3441eb3a47bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Model       MSE\n",
      "0  Decision Tree  0.495235\n",
      "1  Random Forest  0.255368\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "24. Train a Random Forest Regressor and compare its performance with a single Decision Tree.\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the California housing dataset\n",
    "california = fetch_california_housing()\n",
    "X, y = california.data, california.target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train a Decision Tree Regressor\n",
    "tree_regressor = DecisionTreeRegressor(random_state=42)\n",
    "tree_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Create and train a Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "tree_pred = tree_regressor.predict(X_test)\n",
    "rf_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "# Calculate MSE for both models\n",
    "tree_mse = mean_squared_error(y_test, tree_pred)\n",
    "rf_mse = mean_squared_error(y_test, rf_pred)\n",
    "\n",
    "# Create a DataFrame to compare performance\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Decision Tree', 'Random Forest'],\n",
    "    'MSE': [tree_mse, rf_mse]\n",
    "})\n",
    "\n",
    "# Print the results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b775d5d-8022-4db4-8dc5-4d1d1c68bbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-Bag Score: 0.961335676625659\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier.\n",
    "'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "breast_cancer = load_breast_cancer()\n",
    "X, y = breast_cancer.data, breast_cancer.target\n",
    "\n",
    "# Create a Random Forest Classifier with oob_score enabled\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(X, y)\n",
    "\n",
    "# Get the OOB score\n",
    "oob_score = rf_classifier.oob_score_\n",
    "\n",
    "# Print the OOB score\n",
    "print(f\"Out-of-Bag Score: {oob_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffcd0a07-38c4-4a65-ac3c-d06a6a92f9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9415204678362573\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "26. Train a Bagging Classifier using SVM as a base estimator and print accuracy.\n",
    "'''\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "breast_cancer = load_breast_cancer()\n",
    "X, y = breast_cancer.data, breast_cancer.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create an SVM classifier as the base estimator\n",
    "estimator = SVC(random_state=42)  \n",
    "\n",
    "# Create a Bagging Classifier with 10 SVM estimators\n",
    "bagging_classifier = BaggingClassifier(estimator=estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the Bagging Classifier\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = bagging_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ad117ca-e676-4178-b9ca-a1933e0dde56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 10 trees: 1.0\n",
      "Accuracy with 50 trees: 1.0\n",
      "Accuracy with 100 trees: 1.0\n",
      "Accuracy with 200 trees: 1.0\n",
      "Best accuracy achieved with 10 trees.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "27. Train a Random Forest Classifier with different numbers of trees and compare accuracy.\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "data['target'] = iris.target\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop('target', axis=1)  # Replace 'target_column' with your target column name\n",
    "y = data['target']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "# Define a list of the number of trees (n_estimators) to try\n",
    "n_estimators_values = [10, 50, 100, 200]\n",
    "\n",
    "# Store accuracy scores for each value of n_estimators\n",
    "accuracy_scores = []\n",
    "\n",
    "# Iterate through different n_estimators values\n",
    "for n_estimators in n_estimators_values:\n",
    "    # Create a Random Forest Classifier with the current n_estimators\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=n_estimators, random_state=42) \n",
    "\n",
    "    # Train the model on the training data\n",
    "    rf_classifier.fit(X_train, y_train)  \n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    y_pred = rf_classifier.predict(X_test)  \n",
    "\n",
    "    # Calculate accuracy and store it\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "    print(f\"Accuracy with {n_estimators} trees: {accuracy}\")\n",
    "\n",
    "# Compare accuracy scores to find the best value for n_estimators\n",
    "best_n_estimators = n_estimators_values[accuracy_scores.index(max(accuracy_scores))]\n",
    "print(f\"Best accuracy achieved with {best_n_estimators} trees.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e20c0ada-7476-4fac-9e6a-b3b9c3c8145f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score.\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "data['target'] = iris.target\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop('target', axis=1)  \n",
    "y = data['target']\n",
    "\n",
    "# Create a binary target variable for class 2\n",
    "y_binary = (y == 2).astype(int) \n",
    "\n",
    "# Split data into training and testing sets using the binary target\n",
    "X_train, X_test, y_train_binary, y_test_binary = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression base estimator\n",
    "base_estimator = LogisticRegression(max_iter=1000) # Increased max_iter for convergence\n",
    "\n",
    "# Create a Bagging Classifier with Logistic Regression as the base estimator\n",
    "bagging_classifier = BaggingClassifier(estimator=base_estimator, n_estimators=10, random_state=42)  \n",
    " \n",
    "\n",
    "# Train the Bagging Classifier using the binary target\n",
    "bagging_classifier.fit(X_train, y_train_binary)\n",
    "\n",
    "# Predict probabilities for the testing set\n",
    "y_pred_proba = bagging_classifier.predict_proba(X_test)[:, 1] \n",
    "\n",
    "# Calculate the AUC score using the binary target\n",
    "auc_score = roc_auc_score(y_test_binary, y_pred_proba)  \n",
    "\n",
    "# Print the AUC score\n",
    "print(f\"AUC Score: {auc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48fd4762-42c1-46ee-abd1-73e82df642ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "29. Train a Random Forest Regressor and analyze feature importance scores.\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance  # Or importances\n",
    "import matplotlib.pyplot as plt # For visualization\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "data['target'] = iris.target\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop('target', axis=1)  \n",
    "y = data['target']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)  \n",
    "\n",
    "# Train the model\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance scores\n",
    "feature_importances = rf_regressor.feature_importances_ \n",
    "# or\n",
    "# result = permutation_importance(rf_regressor, X_test, y_test, n_repeats=10, random_state=42)\n",
    "# feature_importances = result.importances_mean\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "\n",
    "# Sort by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2adcde3-383c-4a36-a654-bdcbce0890e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Accuracy: 1.0\n",
      "Random Forest Classifier Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "30. Train an ensemble model using both Bagging and Random Forest and compare accuracy.\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier # Import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "data['target'] = iris.target\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop('target', axis=1)  \n",
    "y = data['target']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 1. Train Bagging Classifier\n",
    "bagging_classifier = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "bagging_predictions = bagging_classifier.predict(X_test)\n",
    "bagging_accuracy = accuracy_score(y_test, bagging_predictions)\n",
    "\n",
    "# 2. Train Random Forest Classifier\n",
    "random_forest_classifier = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "random_forest_classifier.fit(X_train, y_train)\n",
    "random_forest_predictions = random_forest_classifier.predict(X_test)\n",
    "random_forest_accuracy = accuracy_score(y_test, random_forest_predictions)\n",
    "\n",
    "# Compare Accuracy\n",
    "print(f\"Bagging Classifier Accuracy: {bagging_accuracy}\")\n",
    "print(f\"Random Forest Classifier Accuracy: {random_forest_accuracy}\")\n",
    "\n",
    "# You can further compare using other metrics like precision, recall, F1-score, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd8bbcab-7b4c-4e03-bae8-3be296964da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "31. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV.\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris # Import load_iris\n",
    "\n",
    "# 1. Load and Prepare Data\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "data['target'] = iris.target #add target to dataframe\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop('target', axis=1)  \n",
    "y = data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Define Hyperparameter Grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# 3. Create and Train GridSearchCV\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, \n",
    "                          cv=5, scoring='accuracy', n_jobs=-1)  # n_jobs=-1 uses all CPU cores\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 4. Get Best Hyperparameters and Model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 5. Evaluate on Test Set\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac31d29b-e4ca-4ce9-8814-15b0f2278873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with 10 base estimators:\n",
      "  Mean Squared Error (MSE): 0.2824242776841025\n",
      "  R-squared (R2): 0.7844762342339637\n",
      "------------------------------\n",
      "Performance with 50 base estimators:\n",
      "  Mean Squared Error (MSE): 0.2572988359842641\n",
      "  R-squared (R2): 0.8036499747356253\n",
      "------------------------------\n",
      "Performance with 100 base estimators:\n",
      "  Mean Squared Error (MSE): 0.2559196347164238\n",
      "  R-squared (R2): 0.8047024715444397\n",
      "------------------------------\n",
      "Performance with 200 base estimators:\n",
      "  Mean Squared Error (MSE): 0.2540787198704185\n",
      "  R-squared (R2): 0.8061073114658485\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "32. Train a Bagging Regressor with different numbers of base estimators and compare performance.\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.datasets import fetch_california_housing # Import fetch_california_housing\n",
    "\n",
    "# 1. Load and Prepare Data\n",
    "# Load the California housing dataset\n",
    "housing = fetch_california_housing()\n",
    "data = pd.DataFrame(data=housing.data, columns=housing.feature_names)\n",
    "data['target'] = housing.target #add target to dataframe\n",
    "\n",
    "X = data.drop('target', axis=1)  \n",
    "y = data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Define a List of Base Estimator Numbers\n",
    "n_estimators_values = [10, 50, 100, 200] \n",
    "\n",
    "# 3. Train and Evaluate Bagging Regressors\n",
    "for n_estimators in n_estimators_values:\n",
    "    # Create a Bagging Regressor with the current n_estimators\n",
    "    bagging_regressor = BaggingRegressor(estimator=DecisionTreeRegressor(), \n",
    "                                        n_estimators=n_estimators, random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    bagging_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = bagging_regressor.predict(X_test)\n",
    "    \n",
    "    # Evaluate performance\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Performance with {n_estimators} base estimators:\")\n",
    "    print(f\"  Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"  R-squared (R2): {r2}\")\n",
    "    print(\"-\" * 30)  # Separator for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "397ad592-4c40-4643-8a0e-656b77bbed48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of misclassified samples: 0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "33. Train a Random Forest Classifier and analyze misclassified samples.\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris # Import load_iris\n",
    "\n",
    "# 1. Load and Prepare Data\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "data['target'] = iris.target #add target to dataframe\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop('target', axis=1)  \n",
    "y = data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Train the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)  \n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 3. Predict and Identify Misclassified Samples\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "misclassified_indices = np.where(y_pred != y_test)[0] \n",
    "misclassified_samples = X_test.iloc[misclassified_indices]\n",
    "\n",
    "# 4. Analyze Misclassified Samples\n",
    "print(f\"Number of misclassified samples: {len(misclassified_indices)}\")\n",
    "\n",
    "# Option 1: Print or inspect misclassified samples\n",
    "# print(misclassified_samples)  # Print the DataFrame of misclassified samples\n",
    "\n",
    "# Option 2: Analyze specific features or patterns\n",
    "# for index in misclassified_indices:\n",
    "#     print(f\"Sample index: {index}, True label: {y_test.iloc[index]}, Predicted label: {y_pred[index]}\")\n",
    "#     print(X_test.iloc[index])  # Print the feature values of the misclassified sample\n",
    "#     print(\"-\" * 20)\n",
    "\n",
    "# Option 3: Visualize misclassified samples (if features are suitable for plotting)\n",
    "# # (Import necessary libraries like matplotlib or seaborn)\n",
    "# # ... plotting code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4796f635-91f8-40db-8793-35b25b1a3141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 1.0\n",
      "Bagging Classifier Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "34. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier.\n",
    "'''\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Bagging Classifier\n",
    "bagging_classifier = BaggingClassifier(DecisionTreeClassifier(random_state=42), \n",
    "                                      n_estimators=10, random_state=42)\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "# Decision Tree predictions\n",
    "dt_predictions = dt_classifier.predict(X_test)\n",
    "\n",
    "# Bagging Classifier predictions\n",
    "bagging_predictions = bagging_classifier.predict(X_test)\n",
    "\n",
    "# Decision Tree accuracy\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy}\")\n",
    "\n",
    "# Bagging Classifier accuracy\n",
    "bagging_accuracy = accuracy_score(y_test, bagging_predictions)\n",
    "print(f\"Bagging Classifier Accuracy: {bagging_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94104d5c-7487-47f0-88e8-f2534e68d749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "35. Train a Random Forest Classifier and visualize the confusion matrix.\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)  # Adjust hyperparameters as needed\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf_classifier.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b84883d3-736c-401d-b363-a6571afdd408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy: 1.0\n",
      "dt Accuracy: 1.0\n",
      "svm Accuracy: 1.0\n",
      "lr Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "36. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy.\n",
    "'''\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler  # For scaling data\n",
    "from sklearn.datasets import load_iris  # For example dataset\n",
    "\n",
    "# Load the Iris dataset (you can replace this with your own data)\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define base estimators\n",
    "estimators = [\n",
    "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "    ('svm', SVC(random_state=42)),\n",
    "    ('lr', LogisticRegression(random_state=42, max_iter=1000)),  # Increased max_iter\n",
    "]\n",
    "\n",
    "# Define the stacking classifier\n",
    "stacking_classifier = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(random_state=42, max_iter=1000)  # Increased max_iter\n",
    ")\n",
    "\n",
    "# Train the stacking classifier\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "stacking_predictions = stacking_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "stacking_accuracy = accuracy_score(y_test, stacking_predictions)\n",
    "print(f\"Stacking Classifier Accuracy: {stacking_accuracy}\")\n",
    "\n",
    "# Compare with individual base estimators\n",
    "for name, estimator in estimators:\n",
    "    estimator.fit(X_train, y_train)\n",
    "    predictions = estimator.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"{name} Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72e8fcb8-c067-47c6-bee4-f52c3db91409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             feature  importance\n",
      "2  petal length (cm)    0.439994\n",
      "3   petal width (cm)    0.421522\n",
      "0  sepal length (cm)    0.108098\n",
      "1   sepal width (cm)    0.030387\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "37. Train a Random Forest Classifier and print the top 5 most important features.\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Assuming you have your data in a pandas DataFrame named 'df'\n",
    "# with features in columns 'feature1', 'feature2', etc., and target in column 'target'\n",
    "\n",
    "# Load your data (replace with your actual data loading)\n",
    "# df = pd.read_csv('your_data.csv')  \n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "X = df[iris.feature_names]  # Features\n",
    "y = df['target']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)  # Adjust hyperparameters as needed\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf_classifier.feature_importances_\n",
    "\n",
    "# Create a DataFrame of feature importances\n",
    "feature_importances = pd.DataFrame({'feature': X.columns, 'importance': importances})\n",
    "\n",
    "# Sort by importance and print top 5\n",
    "top_5_features = feature_importances.sort_values(by='importance', ascending=False).head(5)\n",
    "print(top_5_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c9011c5-6644-4084-9617-3f493f63a9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1-score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "38. Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score.\n",
    "'''\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier  # Or any other base estimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.datasets import load_iris  # For example dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Iris dataset (you can replace this with your own data)\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "# convert the iris dataset to a pandas DataFrame\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Bagging Classifier\n",
    "bagging_classifier = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),  # Changed to 'estimator'\n",
    "    n_estimators=10,  \n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Train the classifier\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = bagging_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')  \n",
    "recall = recall_score(y_test, y_pred, average='weighted')  \n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  \n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0057c87c-0638-4352-8b1f-ea918e1cde30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHFCAYAAAAaD0bAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABAGElEQVR4nO3deXyNZ/7/8ffJniAREZFYErS1U1vtFGOndKWLWlozDLXODOloqbZ0qG7W0qCqxaCUWooi2hFSxK6xL0VsrcQaWa7fH3453x5ZJCSSuF/Px+M8Hr2vc93X/bnOndPzdi/n2IwxRgAAABbilNsFAAAAPGgEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIDyUZs+eLZvNlu5j48aN9r6///67unbtqmLFislms6lz586SpOPHj6t9+/YqUqSIbDabBg0alO11TpkyRbNnz872cW/duqU+ffooMDBQzs7Oevzxx7N9G3mRzWbTqFGjcnQbK1euTHcbNptN/fv3z9HtZ6dly5bJZrPJz89P8fHxuV0O8EC55HYBQE6aNWuWKlSokKq9UqVK9v9+9913tWTJEs2cOVPlypVTkSJFJEmDBw/W1q1bNXPmTBUvXlyBgYHZXt+UKVNUtGhR9ejRI1vHnTp1qj7//HNNnDhRtWrVUsGCBbN1fCtbuXKlJk+enONB60EICwuTdPsfAUuXLlWXLl1yuSLgwSEA4aFWpUoV1a5dO8M+e/fuVbly5fTyyy+nan/iiSfsR4Tyk71798rT0zNfHY3AgxUTE6OVK1eqefPm2rx5s8LCwvJsALp+/bq8vLxyuww8ZDgFBss6fvy4bDab1q1bpwMHDjicHrPZbDp8+LBWrVplbz9+/LgkKS4uTv/4xz9UpkwZubm5qUSJEho0aJCuXbvmMH5ycrImTpyoxx9/XJ6enipcuLDq1aunZcuWSZJCQkK0b98+hYeH27cREhKSYc03b95UaGiow7b79euny5cv2/vYbDZ98cUXunHjhn3cjE6zPfnkk6pSpYoiIiLUoEEDeXp6KiQkRLNmzZIkrVixQjVr1pSXl5eqVq2q1atXO6x/+PBh9ezZU48++qi8vLxUokQJdezYUXv27HHo16dPH3l4eGj79u0Or1GLFi0UEBCgs2fPZjj3P4uLi1Pv3r3l5+enggULqk2bNjp48GCafQ8dOqSXXnpJxYoVk7u7uypWrKjJkyc79EnZ53PnztWQIUNUvHhxeXp6qmnTpoqKirL369Gjh33dP59STfnbSPHVV1+pYsWK8vLyUvXq1fX9999nal4nT57UK6+84lDrhAkTlJycbO+T8nf74Ycf6qOPPlKZMmVUsGBB1a9fX1u2bMnUdiTpyy+/VGJiogYPHqxnnnlGP/74o06cOJGq3+XLlzV06FCVLVtW7u7uKlasmNq1a6dff/3V3ic+Pl6jR49WxYoV5eHhIT8/PzVr1kybN292qDmtv8M7T1uOGjVKNptNO3bs0HPPPSdfX1+VK1dOkrRt2zZ17dpVISEh9r/TF198Mc26T58+rb/+9a8qVaqU3NzcFBQUpOeee07nzp3T1atXVbhwYf3tb39Ltd7x48fl7Oys8ePHZ/q1RD5lgIfQrFmzjCSzZcsWk5CQ4PBITEw0xhhz8+ZNExERYWrUqGHKli1rIiIiTEREhImNjTURERGmePHipmHDhvb2mzdvmmvXrpnHH3/cFC1a1Hz00Udm3bp15tNPPzU+Pj6mefPmJjk52V5Dt27djM1mM6+//rr57rvvzKpVq8z7779vPv30U2OMMTt27DBly5Y1NWrUsG9jx44d6c4pOTnZtG7d2ri4uJi33nrLrFmzxnz44YemQIECpkaNGubmzZvGGGMiIiJMu3btjKenp33c8+fPpztu06ZNjZ+fnylfvrwJCwszP/zwg+nQoYORZN555x1TtWpVM2/ePLNy5UpTr1494+7ubk6fPm1fPzw83AwdOtQsWrTIhIeHmyVLlpjOnTsbT09P8+uvv9r73bhxwzz++OOmbNmy5o8//jDGGPP2228bJycns2bNmkzv2+TkZNOsWTPj7u5u3n//fbNmzRozcuRIU7ZsWSPJjBw50t533759xsfHx1StWtXMmTPHrFmzxgwdOtQ4OTmZUaNG2ftt2LDBSDKlSpUynTp1MsuXLzdz5841jzzyiPH29jZHjhwxxhhz+PBh89xzzxlJ9tc25W/DGGMkmZCQEPPEE0+Y//73v2blypXmySefNC4uLvYx0nP+/HlTokQJ4+/vb6ZNm2ZWr15t+vfvbySZvn372vsdO3bMvp02bdqYpUuXmqVLl5qqVasaX19fc/ny5Uy9jo899pgJDAw0iYmJZt26dUaSw2tijDFxcXGmcuXKpkCBAmb06NHmhx9+MIsXLzYDBw4069evN8YYk5CQYJo1a2ZcXFzMP/7xD7Ny5UqzbNky8+abb5p58+Y51Dxr1qxUddy5z0aOHGkkmeDgYDNs2DCzdu1as3TpUmOMMQsXLjRvv/22WbJkiQkPDzfz5883TZs2Nf7+/ubChQv2MX777TcTGBjo8D5dsGCB6dWrlzlw4IAxxpjBgwebAgUKpHq9/vnPfxoPDw9z8eLFTL2OyL8IQHgopQSgtB7Ozs4OfZs2bWoqV66caozg4GDTvn17h7axY8caJycn88svvzi0L1q0yEgyK1euNMYYs2nTJiPJ/Pvf/86wzsqVK5umTZtmak6rV682ksy4ceMc2hcsWGAkmenTp9vbunfvbgoUKJCpcZs2bWokmW3bttnbLl26ZJydnY2np6dD2Nm5c6eRZD777LN0x0tMTDS3bt0yjz76qBk8eLDDc4cOHTLe3t6mc+fOZt26dcbJycmMGDEiU3WmWLVqlZFkD5Ip3n///VQfpq1btzYlS5Y0sbGxDn379+9vPDw8zO+//26M+b8AVLNmTYcQe/z4cePq6mpef/11e1u/fv1Mev92lGQCAgJMXFycvS0mJsY4OTmZsWPHZjiv4cOHG0lm69atDu19+/Y1NpvNREdHG2P+L0xUrVrVHuaNMSYyMtJIsoeOjKT8fQ4fPtwYcztUlilTxgQHBzvMf/To0UaSWbt2bbpjzZkzx0gyM2bMSLfPvQSgt99++67zSExMNFevXjUFChRw+Hvo1auXcXV1Nfv370933SNHjhgnJyfz8ccf29tu3Lhh/Pz8TM+ePe+6beR/nALDQ23OnDn65ZdfHB5bt2695/G+//57ValSRY8//rgSExPtj9atWzvcXbZq1SpJUr9+/bJjGpKk9evXS1KqC6aff/55FShQQD/++OM9jx0YGKhatWrZl4sUKaJixYrp8ccfV1BQkL29YsWKkuRwyiExMVFjxoxRpUqV5ObmJhcXF7m5uenQoUM6cOCAw3YeeeQRzZgxQ0uXLlWHDh3UuHHjLF9MvGHDBklKdc3WSy+95LB88+ZN/fjjj3r66afl5eXlsL/atWunmzdvpjpl9NJLL8lms9mXg4OD1aBBA/s2M6NZs2YqVKiQfTkgIEDFihVL8zTNn61fv16VKlXSE0884dDeo0cPGWPs+z9F+/bt5ezsbF+uVq2aJN11O9L/Xfzcq1cvSbdPQ/Xo0UMnTpxw+DtatWqVHnvsMf3lL39Jd6xVq1bJw8PDPlZ2efbZZ1O1Xb16VcOGDdMjjzwiFxcXubi4qGDBgrp27ZrD39qqVavUrFkz+99rWsqWLasOHTpoypQpMsZIkr755htdunSJa+csgoug8VCrWLHiXS+Czopz587p8OHDcnV1TfP5ixcvSpIuXLggZ2dnFS9ePNu2fenSJbm4uMjf39+h3WazqXjx4rp06dI9j51y59ufubm5pWp3c3OTdDtcpBgyZIgmT56sYcOGqWnTpvL19ZWTk5Nef/113bhxI9W47du3V0BAgM6dO6chQ4Y4fIhnRsrr4Ofn59B+52t96dIlJSYmauLEiZo4cWKaY6Xsr/TGSGnbtWtXpuu7sy5Jcnd3T/O1uLPetK4BSwmgd+7fO7fj7u4uSXfdzpUrV7Rw4UI98cQT8vf3t18/9vTTT2vUqFEKCwuzB54LFy6odOnSGY534cIFBQUFyckpe/89ndZdly+99JJ+/PFHvfXWW6pTp468vb1ls9nUrl07h3lfuHBBJUuWvOs2Bg4cqBYtWmjt2rVq1aqVJk+erPr166tmzZrZOhfkTQQgIAuKFi0qT09PzZw5M93nJcnf319JSUmKiYnJttvn/fz8lJiYqAsXLjiEIGOMYmJiVKdOnWzZTlbNnTtXr776qsaMGePQfvHiRRUuXDhV/z59+ujKlSuqXLmyBgwYoMaNG8vX1zfT20t5HS5duuQQAmJiYhz6+fr6ytnZWd26dUv3SFyZMmUclu8cI6UtrVCT3fz8/NK8EPzMmTOS/u9v637NmzdP169fV2RkZJqv+5IlS/THH3/I19dX/v7++u233zIcz9/fXz///LOSk5PTDUEeHh6SlOq7hjIK7X8+EidJsbGx+v777zVy5EgNHz7c3h4fH6/ff/89VU13q1uSmjdvripVqmjSpEkqWLCgduzYoblz5951PTwcOAUGZEGHDh105MgR+fn5qXbt2qkeKf+Cb9u2raTb38eTkcwcGUjRokULSUr1P+jFixfr2rVr9ucfNJvNZj/6kGLFihU6ffp0qr5ffPGF5s6dq0mTJmnZsmW6fPmyevbsmaXtNWvWTJL09ddfO7R/8803DsteXl5q1qyZoqKiVK1atTT3153BZt68efbTIdLt00mbN2/Wk08+aW/L7JGWrGrRooX279+vHTt2OLTPmTNHNpvNPu/7FRYWpkKFCunHH3/Uhg0bHB7jx49XfHy8/bVt27atDh48mOr025+1bdtWN2/ezPBOw4CAAHl4eGj37t0O7d99912m67bZbDLGpPpb++KLL5SUlJSqpg0bNig6Ovqu4w4YMEArVqxQaGioAgIC9Pzzz2e6JuRvHAHCQ23v3r1KTExM1V6uXLlUp5IyY9CgQVq8eLGaNGmiwYMHq1q1akpOTtbJkye1Zs0aDR06VHXr1lXjxo3VrVs3vffeezp37pw6dOggd3d3RUVFycvLS2+88YYkqWrVqpo/f74WLFigsmXLysPDQ1WrVk1z2y1btlTr1q01bNgwxcXFqWHDhtq9e7dGjhypGjVqqFu3blmeT3bo0KGDZs+erQoVKqhatWravn27xo8fn+oUxJ49ezRgwAB1797dHnrCwsL03HPP6ZNPPsn0N223atVKTZo00b/+9S9du3ZNtWvX1v/+9z999dVXqfp++umnatSokRo3bqy+ffsqJCREV65c0eHDh7V8+fJUH+znz5/X008/rd69eys2NlYjR46Uh4eHQkND7X1S9s9//vMftW3bVs7OzqpWrZr99OC9Gjx4sObMmaP27dtr9OjRCg4O1ooVKzRlyhT17dtXjz322H2NL91+P0RGRqpv375q3rx5qucbNmyoCRMmKCwsTP3799egQYO0YMECderUScOHD9cTTzyhGzduKDw8XB06dFCzZs304osvatasWerTp4+io6PVrFkzJScna+vWrapYsaK6du0qm82mV155xf5lo9WrV1dkZGSq0JoRb29vNWnSROPHj1fRokUVEhKi8PBwhYWFpTrSOHr0aK1atUpNmjTRm2++qapVq+ry5ctavXq1hgwZ4vDlqK+88opCQ0O1adMmjRgx4r73I/KRXL0EG8ghGd0FpjvuWMnKXWDGGHP16lUzYsQIU758eePm5ma/zXrw4MEmJibG3i8pKcl8/PHHpkqVKvZ+9evXN8uXL7f3OX78uGnVqpUpVKiQ/dbfjNy4ccMMGzbMBAcHG1dXVxMYGGj69u1rv608RVbvAsvK/CWZfv362Zf/+OMP89prr5lixYoZLy8v06hRI/PTTz+Zpk2b2u9wu3r1qqlQoYKpVKmSuXbtmsN4/fr1M66urqnufsrI5cuXTa9evUzhwoWNl5eXadmypfn1119T3VFkzO07kHr16mVKlChhXF1djb+/v2nQoIF577337H1S7gL76quvzIABA4y/v79xd3c3jRs3drg7zhhj4uPjzeuvv278/f2NzWYzksyxY8fSfG3+/Fp27979rvM6ceKEeemll4yfn59xdXU15cuXN+PHjzdJSUkO85Fkxo8fn2r9tOb/Z4MGDTKSzM6dO9Ptk3I32vbt240xt/fvwIEDTenSpY2rq6spVqyYad++faqvOHj77bfNo48+atzc3Iyfn59p3ry52bx5s71PbGysef31101AQIApUKCA6dixozl+/Hi6d4H9+bb2FL/99pt59tlnja+vrylUqJBp06aN2bt3b5qv76lTp0yvXr1M8eLFjaurqwkKCjIvvPCCOXfuXKpxe/ToYVxcXMxvv/2W7uuCh4/NmD8d7wUAC9q4caOaNWumhQsX6rnnnsvtcvAA3bp1SyEhIWrUqJH++9//5nY5eIA4BQYAsJwLFy4oOjpas2bN0rlz5xwurIY1EIAA5BlpXa/1Z05OTtl+uzWsacWKFerZs6cCAwM1ZcoUbn23IE6BAcgz7rz1+U7du3fP8G4jAMgsjgAByDN++eWXDJ/Pru/CAQCOAAEAAMvhZDoAALAcToGlITk5WWfOnFGhQoXuek0CAADIG4wxunLlSqZ+n44AlIYzZ86oVKlSuV0GAAC4B6dOnbrrD+ISgNJQqFAhSbdfQG9v71yuBgAAZEZcXJxKlSpl/xzPCAEoDSmnvby9vQlAAADkM5m5fIWLoAEAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOXkagDatGmTOnbsqKCgINlsNi1duvSu64SHh6tWrVry8PBQ2bJlNW3atHT7zp8/XzabTZ07d86+ogEAQL6XqwHo2rVrql69uiZNmpSp/seOHVO7du3UuHFjRUVF6c0339SAAQO0ePHiVH1PnDihf/zjH2rcuHF2lw0AAPI5l9zceNu2bdW2bdtM9582bZpKly6tTz75RJJUsWJFbdu2TR9++KGeffZZe7+kpCS9/PLLeuedd/TTTz/p8uXL2Vw5AADIz/LVNUARERFq1aqVQ1vr1q21bds2JSQk2NtGjx4tf39/vfbaa5kaNz4+XnFxcQ4PAADw8MpXASgmJkYBAQEObQEBAUpMTNTFixclSf/73/8UFhamGTNmZHrcsWPHysfHx/4oVapUttYNAADylnwVgCTJZrM5LBtj7O1XrlzRK6+8ohkzZqho0aKZHjM0NFSxsbH2x6lTp7K1ZgAAkLfk6jVAWVW8eHHFxMQ4tJ0/f14uLi7y8/PTvn37dPz4cXXs2NH+fHJysiTJxcVF0dHRKleuXKpx3d3d5e7unrPFAwCAPCNfBaD69etr+fLlDm1r1qxR7dq15erqqgoVKmjPnj0Oz48YMUJXrlzRp59+yqktAAAgKZcD0NWrV3X48GH78rFjx7Rz504VKVJEpUuXVmhoqE6fPq05c+ZIkvr06aNJkyZpyJAh6t27tyIiIhQWFqZ58+ZJkjw8PFSlShWHbRQuXFiSUrUDAADrytUAtG3bNjVr1sy+PGTIEElS9+7dNXv2bJ09e1YnT560P1+mTBmtXLlSgwcP1uTJkxUUFKTPPvvM4RZ4AACAu7GZlKuIYRcXFycfHx/FxsbK29s7t8sBAACZkJXP73x3FxgAAMD9IgABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLydUAtGnTJnXs2FFBQUGy2WxaunTpXdcJDw9XrVq15OHhobJly2ratGkOz8+YMUONGzeWr6+vfH199Ze//EWRkZE5NAMAAJAf5WoAunbtmqpXr65JkyZlqv+xY8fUrl07NW7cWFFRUXrzzTc1YMAALV682N5n48aNevHFF7VhwwZFRESodOnSatWqlU6fPp1T0wAAAPmMzRhjcrsISbLZbFqyZIk6d+6cbp9hw4Zp2bJlOnDggL2tT58+2rVrlyIiItJcJykpSb6+vpo0aZJeffXVTNUSFxcnHx8fxcbGytvbO0vzAAAAuSMrn9/56hqgiIgItWrVyqGtdevW2rZtmxISEtJc5/r160pISFCRIkUeRIkAACAfcMntArIiJiZGAQEBDm0BAQFKTEzUxYsXFRgYmGqd4cOHq0SJEvrLX/6S7rjx8fGKj4+3L8fFxWVf0QAAIM/JV0eApNunyv4s5Qzene2SNG7cOM2bN0/ffvutPDw80h1z7Nix8vHxsT9KlSqVvUUDAIA8JV8FoOLFiysmJsah7fz583JxcZGfn59D+4cffqgxY8ZozZo1qlatWobjhoaGKjY21v44depUttcOAADyjnx1Cqx+/fpavny5Q9uaNWtUu3Ztubq62tvGjx+v9957Tz/88INq165913Hd3d3l7u6e7fUCAIC8KVePAF29elU7d+7Uzp07Jd2+zX3nzp06efKkpNtHZv5851afPn104sQJDRkyRAcOHNDMmTMVFhamf/zjH/Y+48aN04gRIzRz5kyFhIQoJiZGMTExunr16gOdGwAAyLty9Tb4jRs3qlmzZqnau3fvrtmzZ6tHjx46fvy4Nm7caH8uPDxcgwcP1r59+xQUFKRhw4apT58+9udDQkJ04sSJVGOOHDlSo0aNylRd3AYPAED+k5XP7zzzPUB5CQEIAID856H9HiAAAIDsQAACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWk+UAFBISotGjR+vkyZM5UQ8AAECOy3IAGjp0qL777juVLVtWLVu21Pz58xUfH58TtQEAAOSILAegN954Q9u3b9f27dtVqVIlDRgwQIGBgerfv7927NiREzUCAABkK5sxxtzPAAkJCZoyZYqGDRumhIQEValSRQMHDlTPnj1ls9myq84HKi4uTj4+PoqNjZW3t3dulwMAADIhK5/fLve6kYSEBC1ZskSzZs3S2rVrVa9ePb322ms6c+aM/v3vf2vdunX65ptv7nV4AACAHJPlALRjxw7NmjVL8+bNk7Ozs7p166aPP/5YFSpUsPdp1aqVmjRpkq2FAgAAZJcsB6A6deqoZcuWmjp1qjp37ixXV9dUfSpVqqSuXbtmS4EAAADZLcsB6OjRowoODs6wT4ECBTRr1qx7LgoAACAnZfkusPPnz2vr1q2p2rdu3apt27ZlS1EAAAA5KcsBqF+/fjp16lSq9tOnT6tfv37ZUhQAAEBOynIA2r9/v2rWrJmqvUaNGtq/f3+2FAUAAJCTshyA3N3dde7cuVTtZ8+elYvLPd9VDwAA8MBkOQC1bNlSoaGhio2NtbddvnxZb775plq2bJmtxQEAAOSELB+ymTBhgpo0aaLg4GDVqFFDkrRz504FBAToq6++yvYCAQAAsluWA1CJEiW0e/duff3119q1a5c8PT3Vs2dPvfjii2l+JxAAAEBec08X7RQoUEB//etfs7sWAACAB+Ker1rev3+/Tp48qVu3bjm0P/XUU/ddFAAAQE66p2+Cfvrpp7Vnzx7ZbDal/Jh8yi+/JyUlZW+FAAAA2SzLd4ENHDhQZcqU0blz5+Tl5aV9+/Zp06ZNql27tjZu3JgDJQIAAGSvLB8BioiI0Pr16+Xv7y8nJyc5OTmpUaNGGjt2rAYMGKCoqKicqBMAACDbZPkIUFJSkgoWLChJKlq0qM6cOSNJCg4OVnR0dPZWBwAAkAOyfASoSpUq2r17t8qWLau6detq3LhxcnNz0/Tp01W2bNmcqBEAACBbZTkAjRgxQteuXZMkvffee+rQoYMaN24sPz8/LViwINsLBAAAyG42k3Ib1334/fff5evra78TLL+Li4uTj4+PYmNj5e3tndvlAACATMjK53eWrgFKTEyUi4uL9u7d69BepEiRhyb8AACAh1+WApCLi4uCg4Oz7bt+Nm3apI4dOyooKEg2m01Lly696zrh4eGqVauWPDw8VLZsWU2bNi1Vn8WLF6tSpUpyd3dXpUqVtGTJkmypFwAAPByyfBfYiBEjFBoaqt9///2+N37t2jVVr15dkyZNylT/Y8eOqV27dmrcuLGioqL05ptvasCAAVq8eLG9T0REhLp06aJu3bpp165d6tatm1544QVt3br1vusFAAAPhyxfA1SjRg0dPnxYCQkJCg4OVoECBRye37Fjx70VYrNpyZIl6ty5c7p9hg0bpmXLlunAgQP2tj59+mjXrl2KiIiQJHXp0kVxcXFatWqVvU+bNm3k6+urefPmZaqWnLoGyBijGwl8UzYAAJLk6eqcrZfQZOXzO8t3gWUUUHJaRESEWrVq5dDWunVrhYWFKSEhQa6uroqIiNDgwYNT9fnkk0/SHTc+Pl7x8fH25bi4uGytO8WNhCRVevuHHBkbAID8Zv/o1vJyu+efJb0vWd7qyJEjc6KOTImJiVFAQIBDW0BAgBITE3Xx4kUFBgam2ycmJibdcceOHat33nknR2oGAAB5T+7Ervtw56GyO3+MNb0+GR1iCw0N1ZAhQ+zLcXFxKlWqVHaU68DT1Vn7R7fO9nEBAMiPPF2dc23bWQ5ATk5OGYaJnPw1+OLFi6c6knP+/Hm5uLjIz88vwz53HhX6M3d3d7m7u2d/wXew2Wy5dqgPAAD8nyx/Gt95S3lCQoKioqL05Zdf5vhppPr162v58uUObWvWrFHt2rXl6upq77N27VqH64DWrFmjBg0a5GhtAAAg/8hyAOrUqVOqtueee06VK1fWggUL9Nprr2V6rKtXr+rw4cP25WPHjmnnzp0qUqSISpcurdDQUJ0+fVpz5syRdPuOr0mTJmnIkCHq3bu3IiIiFBYW5nB318CBA9WkSRP95z//UadOnfTdd99p3bp1+vnnn7M6VQAA8JDKlp/CkKQjR46oWrVq9t8Jy4yNGzeqWbNmqdq7d++u2bNnq0ePHjp+/Lg2btxofy48PFyDBw/Wvn37FBQUpGHDhqlPnz4O6y9atEgjRozQ0aNHVa5cOb3//vt65plnMl0XP4UBAED+k5XP72wJQDdu3FBoaKhWrVql6Ojo+x0u1xGAAADIf3L0e4Du/NFTY4yuXLkiLy8vzZ07N+vVAgAAPGBZDkAff/yxQwBycnKSv7+/6tatK19f32wtDgAAICdkOQD16NEjB8oAAAB4cLL8Y6izZs3SwoULU7UvXLhQX375ZbYUBQAAkJOyHIA++OADFS1aNFV7sWLFNGbMmGwpCgAAICdlOQCdOHFCZcqUSdUeHByskydPZktRAAAAOSnLAahYsWLavXt3qvZdu3bZf44CAAAgL8tyAOratasGDBigDRs2KCkpSUlJSVq/fr0GDhyorl275kSNAAAA2SrLd4G99957OnHihFq0aCEXl9urJycn69VXX+UaIAAAkC/c8zdBHzp0SDt37pSnp6eqVq2q4ODg7K4t1/BN0AAA5D85+k3QKR599FE9+uij97o6AABArsnyNUDPPfecPvjgg1Tt48eP1/PPP58tRQEAAOSkLAeg8PBwtW/fPlV7mzZttGnTpmwpCgAAICdlOQBdvXpVbm5uqdpdXV0VFxeXLUUBAADkpCwHoCpVqmjBggWp2ufPn69KlSplS1EAAAA5KcsXQb/11lt69tlndeTIETVv3lyS9OOPP+qbb77RokWLsr1AAACA7JblAPTUU09p6dKlGjNmjBYtWiRPT09Vr15d69ev55ZxAACQL9zz9wCluHz5sr7++muFhYVp165dSkpKyq7acg3fAwQAQP6Tlc/vLF8DlGL9+vV65ZVXFBQUpEmTJqldu3batm3bvQ4HAADwwGTpFNhvv/2m2bNna+bMmbp27ZpeeOEFJSQkaPHixVwADQAA8o1MHwFq166dKlWqpP3792vixIk6c+aMJk6cmJO1AQAA5IhMHwFas2aNBgwYoL59+/ITGAAAIF/L9BGgn376SVeuXFHt2rVVt25dTZo0SRcuXMjJ2gAAAHJEpgNQ/fr1NWPGDJ09e1Z/+9vfNH/+fJUoUULJyclau3atrly5kpN1AgAAZJv7ug0+OjpaYWFh+uqrr3T58mW1bNlSy5Yty876cgW3wQMAkP88kNvgJal8+fIaN26cfvvtN82bN+9+hgIAAHhg7vuLEB9GHAECACD/eWBHgAAAAPIjAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALCcXA9AU6ZMUZkyZeTh4aFatWrpp59+yrD/5MmTVbFiRXl6eqp8+fKaM2dOqj6ffPKJypcvL09PT5UqVUqDBw/WzZs3c2oKAAAgn3HJzY0vWLBAgwYN0pQpU9SwYUN9/vnnatu2rfbv36/SpUun6j916lSFhoZqxowZqlOnjiIjI9W7d2/5+vqqY8eOkqSvv/5aw4cP18yZM9WgQQMdPHhQPXr0kCR9/PHHD3J6AAAgj7IZY0xubbxu3bqqWbOmpk6dam+rWLGiOnfurLFjx6bq36BBAzVs2FDjx4+3tw0aNEjbtm3Tzz//LEnq37+/Dhw4oB9//NHeZ+jQoYqMjLzr0aUUcXFx8vHxUWxsrLy9ve91egAA4AHKyud3rp0Cu3XrlrZv365WrVo5tLdq1UqbN29Oc534+Hh5eHg4tHl6eioyMlIJCQmSpEaNGmn79u2KjIyUJB09elQrV65U+/bt060lPj5ecXFxDg8AAPDwyrUAdPHiRSUlJSkgIMChPSAgQDExMWmu07p1a33xxRfavn27jDHatm2bZs6cqYSEBF28eFGS1LVrV7377rtq1KiRXF1dVa5cOTVr1kzDhw9Pt5axY8fKx8fH/ihVqlT2TRQAAOQ5uX4RtM1mc1g2xqRqS/HWW2+pbdu2qlevnlxdXdWpUyf79T3Ozs6SpI0bN+r999/XlClTtGPHDn377bf6/vvv9e6776ZbQ2hoqGJjY+2PU6dOZc/kAABAnpRrAaho0aJydnZOdbTn/PnzqY4KpfD09NTMmTN1/fp1HT9+XCdPnlRISIgKFSqkokWLSrodkrp166bXX39dVatW1dNPP60xY8Zo7NixSk5OTnNcd3d3eXt7OzwAAMDDK9cCkJubm2rVqqW1a9c6tK9du1YNGjTIcF1XV1eVLFlSzs7Omj9/vjp06CAnp9tTuX79uv2/Uzg7O8sYo1y83hsAAOQhuXob/JAhQ9StWzfVrl1b9evX1/Tp03Xy5En16dNH0u1TU6dPn7Z/18/BgwcVGRmpunXr6o8//tBHH32kvXv36ssvv7SP2bFjR3300UeqUaOG6tatq8OHD+utt97SU089ZT9NBgAArC1XA1CXLl106dIljR49WmfPnlWVKlW0cuVKBQcHS5LOnj2rkydP2vsnJSVpwoQJio6Olqurq5o1a6bNmzcrJCTE3mfEiBGy2WwaMWKETp8+LX9/f3Xs2FHvv//+g54eAADIo3L1e4DyKr4HCACA/CdffA8QAABAbiEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAy8n1ADRlyhSVKVNGHh4eqlWrln766acM+0+ePFkVK1aUp6enypcvrzlz5qTqc/nyZfXr10+BgYHy8PBQxYoVtXLlypyaAgAAyGdccnPjCxYs0KBBgzRlyhQ1bNhQn3/+udq2bav9+/erdOnSqfpPnTpVoaGhmjFjhurUqaPIyEj17t1bvr6+6tixoyTp1q1batmypYoVK6ZFixapZMmSOnXqlAoVKvSgpwcAAPIomzHG5NbG69atq5o1a2rq1Kn2tooVK6pz584aO3Zsqv4NGjRQw4YNNX78eHvboEGDtG3bNv3888+SpGnTpmn8+PH69ddf5erqek91xcXFycfHR7GxsfL29r6nMQAAwIOVlc/vXDsFduvWLW3fvl2tWrVyaG/VqpU2b96c5jrx8fHy8PBwaPP09FRkZKQSEhIkScuWLVP9+vXVr18/BQQEqEqVKhozZoySkpLSrSU+Pl5xcXEODwAA8PDKtQB08eJFJSUlKSAgwKE9ICBAMTExaa7TunVrffHFF9q+fbuMMdq2bZtmzpyphIQEXbx4UZJ09OhRLVq0SElJSVq5cqVGjBihCRMm6P3330+3lrFjx8rHx8f+KFWqVPZNFAAA5Dm5fhG0zWZzWDbGpGpL8dZbb6lt27aqV6+eXF1d1alTJ/Xo0UOS5OzsLElKTk5WsWLFNH36dNWqVUtdu3bVv//9b4fTbHcKDQ1VbGys/XHq1KnsmRwAAMiTci0AFS1aVM7OzqmO9pw/fz7VUaEUnp6emjlzpq5fv67jx4/r5MmTCgkJUaFChVS0aFFJUmBgoB577DF7IJJuX1cUExOjW7dupTmuu7u7vL29HR4AAODhlWsByM3NTbVq1dLatWsd2teuXasGDRpkuK6rq6tKliwpZ2dnzZ8/Xx06dJCT0+2pNGzYUIcPH1ZycrK9/8GDBxUYGCg3N7fsnwgAAMh3cvUU2JAhQ/TFF19o5syZOnDggAYPHqyTJ0+qT58+km6fmnr11Vft/Q8ePKi5c+fq0KFDioyMVNeuXbV3716NGTPG3qdv3766dOmSBg4cqIMHD2rFihUaM2aM+vXr98DnBwAA8qZc/R6gLl266NKlSxo9erTOnj2rKlWqaOXKlQoODpYknT17VidPnrT3T0pK0oQJExQdHS1XV1c1a9ZMmzdvVkhIiL1PqVKltGbNGg0ePFjVqlVTiRIlNHDgQA0bNuxBTw8AAORRufo9QHkV3wMEAED+ky++BwgAACC3EIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDluOR2AXmRMUaSFBcXl8uVAACAzEr53E75HM8IASgNV65ckSSVKlUqlysBAABZdeXKFfn4+GTYx2YyE5MsJjk5WWfOnFGhQoVks9lyu5wcExcXp1KlSunUqVPy9vbO7XJynJXmy1wfXlaaL3N9eOXUfI0xunLlioKCguTklPFVPhwBSoOTk5NKliyZ22U8MN7e3pZ4w6Ww0nyZ68PLSvNlrg+vnJjv3Y78pOAiaAAAYDkEIAAAYDkEIAtzd3fXyJEj5e7untulPBBWmi9zfXhZab7M9eGVF+bLRdAAAMByOAIEAAAshwAEAAAshwAEAAAshwAEAAAshwD0kBo7dqzq1KmjQoUKqVixYurcubOio6MzXGfjxo2y2WypHr/++usDqvrejRo1KlXdxYsXz3Cd8PBw1apVSx4eHipbtqymTZv2gKq9PyEhIWnup379+qXZPz/t102bNqljx44KCgqSzWbT0qVLHZ43xmjUqFEKCgqSp6ennnzySe3bt++u4y5evFiVKlWSu7u7KlWqpCVLluTQDLImo/kmJCRo2LBhqlq1qgoUKKCgoCC9+uqrOnPmTIZjzp49O839ffPmzRyeTcbutm979OiRquZ69erdddy8uG/vNte09o/NZtP48ePTHTOv7tfMfNbk1fctAeghFR4ern79+mnLli1au3atEhMT1apVK127du2u60ZHR+vs2bP2x6OPPvoAKr5/lStXdqh7z5496fY9duyY2rVrp8aNGysqKkpvvvmmBgwYoMWLFz/Aiu/NL7/84jDPtWvXSpKef/75DNfLD/v12rVrql69uiZNmpTm8+PGjdNHH32kSZMm6ZdfflHx4sXVsmVL++/3pSUiIkJdunRRt27dtGvXLnXr1k0vvPCCtm7dmlPTyLSM5nv9+nXt2LFDb731lnbs2KFvv/1WBw8e1FNPPXXXcb29vR329dmzZ+Xh4ZETU8i0u+1bSWrTpo1DzStXrsxwzLy6b+821zv3zcyZM2Wz2fTss89mOG5e3K+Z+azJs+9bA0s4f/68kWTCw8PT7bNhwwYjyfzxxx8PrrBsMnLkSFO9evVM9//Xv/5lKlSo4ND2t7/9zdSrVy+bK8t5AwcONOXKlTPJyclpPp9f96sks2TJEvtycnKyKV68uPnggw/sbTdv3jQ+Pj5m2rRp6Y7zwgsvmDZt2ji0tW7d2nTt2jXba74fd843LZGRkUaSOXHiRLp9Zs2aZXx8fLK3uGyW1ly7d+9uOnXqlKVx8sO+zcx+7dSpk2nevHmGffLDfjUm9WdNXn7fcgTIImJjYyVJRYoUuWvfGjVqKDAwUC1atNCGDRtyurRsc+jQIQUFBalMmTLq2rWrjh49mm7fiIgItWrVyqGtdevW2rZtmxISEnK61Gxz69YtzZ07V7169brrD/fm1/2a4tixY4qJiXHYb+7u7mratKk2b96c7nrp7euM1smrYmNjZbPZVLhw4Qz7Xb16VcHBwSpZsqQ6dOigqKioB1Pgfdq4caOKFSumxx57TL1799b58+cz7P8w7Ntz585pxYoVeu211+7aNz/s1zs/a/Ly+5YAZAHGGA0ZMkSNGjVSlSpV0u0XGBio6dOna/Hixfr2229Vvnx5tWjRQps2bXqA1d6bunXras6cOfrhhx80Y8YMxcTEqEGDBrp06VKa/WNiYhQQEODQFhAQoMTERF28ePFBlJwtli5dqsuXL6tHjx7p9snP+/XPYmJiJCnN/ZbyXHrrZXWdvOjmzZsaPny4XnrppQx/PLJChQqaPXu2li1bpnnz5snDw0MNGzbUoUOHHmC1Wde2bVt9/fXXWr9+vSZMmKBffvlFzZs3V3x8fLrrPAz79ssvv1ShQoX0zDPPZNgvP+zXtD5r8vL7ll+Dt4D+/ftr9+7d+vnnnzPsV758eZUvX96+XL9+fZ06dUoffvihmjRpktNl3pe2bdva/7tq1aqqX7++ypUrpy+//FJDhgxJc507j5iY//+l6Hc7kpKXhIWFqW3btgoKCkq3T37er2lJa7/dbZ/dyzp5SUJCgrp27ark5GRNmTIlw7716tVzuHi4YcOGqlmzpiZOnKjPPvssp0u9Z126dLH/d5UqVVS7dm0FBwdrxYoVGYaD/L5vZ86cqZdffvmu1/Lkh/2a0WdNXnzfcgToIffGG29o2bJl2rBhg0qWLJnl9evVq5en/oWRWQUKFFDVqlXTrb148eKp/iVx/vx5ubi4yM/P70GUeN9OnDihdevW6fXXX8/yuvlxv6bc1ZfWfrvzX4p3rpfVdfKShIQEvfDCCzp27JjWrl2b4dGftDg5OalOnTr5bn8HBgYqODg4w7rz+7796aefFB0dfU/v4by2X9P7rMnL71sC0EPKGKP+/fvr22+/1fr161WmTJl7GicqKkqBgYHZXF3Oi4+P14EDB9KtvX79+va7p1KsWbNGtWvXlqur64Mo8b7NmjVLxYoVU/v27bO8bn7cr2XKlFHx4sUd9tutW7cUHh6uBg0apLteevs6o3XyipTwc+jQIa1bt+6ewrkxRjt37sx3+/vSpUs6depUhnXn530r3T6CW6tWLVWvXj3L6+aV/Xq3z5o8/b7Ntsupkaf07dvX+Pj4mI0bN5qzZ8/aH9evX7f3GT58uOnWrZt9+eOPPzZLliwxBw8eNHv37jXDhw83kszixYtzYwpZMnToULNx40Zz9OhRs2XLFtOhQwdTqFAhc/z4cWNM6rkePXrUeHl5mcGDB5v9+/ebsLAw4+rqahYtWpRbU8iSpKQkU7p0aTNs2LBUz+Xn/XrlyhUTFRVloqKijCTz0UcfmaioKPtdTx988IHx8fEx3377rdmzZ4958cUXTWBgoImLi7OP0a1bNzN8+HD78v/+9z/j7OxsPvjgA3PgwAHzwQcfGBcXF7Nly5YHPr87ZTTfhIQE89RTT5mSJUuanTt3OryP4+Pj7WPcOd9Ro0aZ1atXmyNHjpioqCjTs2dP4+LiYrZu3ZobU7TLaK5XrlwxQ4cONZs3bzbHjh0zGzZsMPXr1zclSpTIl/v2bn/HxhgTGxtrvLy8zNSpU9McI7/s18x81uTV9y0B6CElKc3HrFmz7H26d+9umjZtal/+z3/+Y8qVK2c8PDyMr6+vadSokVmxYsWDL/4edOnSxQQGBhpXV1cTFBRknnnmGbNv3z7783fO1RhjNm7caGrUqGHc3NxMSEhIuv8jyot++OEHI8lER0enei4/79eUW/bvfHTv3t0Yc/uW2pEjR5rixYsbd3d306RJE7Nnzx6HMZo2bWrvn2LhwoWmfPnyxtXV1VSoUCHPhL+M5nvs2LF038cbNmywj3HnfAcNGmRKly5t3NzcjL+/v2nVqpXZvHnzg5/cHTKa6/Xr102rVq2Mv7+/cXV1NaVLlzbdu3c3J0+edBgjv+zbu/0dG2PM559/bjw9Pc3ly5fTHCO/7NfMfNbk1fet7f9PAAAAwDK4BggAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQiA5c2ePVuFCxd+INvq0aOHOnfu/EC2BSB9BCAAyAHHjx+XzWbTzp07c7sUAGkgAAEAAMshAAHIUU8++aTeeOMNDRo0SL6+vgoICND06dN17do19ezZU4UKFVK5cuW0atUqSVJSUpJee+01lSlTRp6enipfvrw+/fRT+3g3b95U5cqV9de//tXeduzYMfn4+GjGjBmZqmn27NkqXbq0vLy89PTTT+vSpUup+ixfvly1atWSh4eHypYtq3feeUeJiYn25202m6ZOnaq2bdvK09NTZcqU0cKFC+3Pp/wqdo0aNWSz2fTkk086jP/hhx8qMDBQfn5+6tevnxISEjJVO4Bskq2/LAYAd2jatKkpVKiQeffdd83BgwfNu+++a5ycnEzbtm3N9OnTzcGDB03fvn2Nn5+fuXbtmrl165Z5++23TWRkpDl69KiZO3eu8fLyMgsWLLCPGRUVZdzc3MySJUtMYmKiadiwoenUqVOm6tmyZYux2Wxm7NixJjo62nz66aemcOHCxsfHx95n9erVxtvb28yePdscOXLErFmzxoSEhJhRo0bZ+0gyfn5+ZsaMGSY6OtqMGDHCODs7m/379xtjjImMjDSSzLp168zZs2fNpUuXjDG3f6zW29vb9OnTxxw4cMAsX77ceHl5menTp9//iw0g0whAAHJU06ZNTaNGjezLiYmJpkCBAqZbt272trNnzxpJJiIiIs0x/v73v5tnn33WoW3cuHGmaNGi5o033jDFixc3Fy5cyFQ9L774omnTpo1DW5cuXRwCUOPGjc2YMWMc+nz11VcmMDDQvizJ9OnTx6FP3bp1Td++fY0xxv5r7lFRUQ59unfvboKDg01iYqK97fnnnzddunTJVP0AsgenwADkuGrVqtn/29nZWX5+fqpataq9LSAgQJJ0/vx5SdK0adNUu3Zt+fv7q2DBgpoxY4ZOnjzpMObQoUNVvnx5TZw4UbNmzVLRokUzVcuBAwdUv359h7Y7l7dv367Ro0erYMGC9kfv3r119uxZXb9+Pd316tevrwMHDty1hsqVK8vZ2dm+HBgYaJ87gAfDJbcLAPDwc3V1dVi22WwObTabTZKUnJys//73vxo8eLAmTJig+vXrq1ChQho/fry2bt3qMMb58+cVHR0tZ2dnHTp0SG3atMlULcaYu/ZJTk7WO++8o2eeeSbVcx4eHhmumzKXjKT1eiQnJ991PQDZhwAEIE/56aef1KBBA/3973+3tx05ciRVv169eqlKlSrq3bu3XnvtNbVo0UKVKlW66/iVKlXSli1bHNruXK5Zs6aio6P1yCOPZDjWli1b9Oqrrzos16hRQ5Lk5uYm6fZF3QDyHgIQgDzlkUce0Zw5c/TDDz+oTJky+uqrr/TLL7/Y76qSpMmTJysiIkK7d+9WqVKltGrVKr388svaunWrPXikZ8CAAWrQoIHGjRunzp07a82aNVq9erVDn7ffflsdOnRQqVKl9Pzzz8vJyUm7d+/Wnj179N5779n7LVy4ULVr11ajRo309ddfKzIyUmFhYZKkYsWKydPTU6tXr1bJkiXl4eEhHx+fbHylANwPrgECkKf06dNHzzzzjLp06aK6devq0qVLDkeDfv31V/3zn//UlClTVKpUKUm3A9Hly5f11ltv3XX8evXq6YsvvtDEiRP1+OOPa82aNRoxYoRDn9atW+v777/X2rVrVadOHdWrV08fffSRgoODHfq98847mj9/vqpVq6Yvv/xSX3/9tf0olIuLiz777DN9/vnnCgoKUqdOne73pQGQjWwmMyfEAQAObDablixZws9aAPkUR4AAAIDlEIAAPFTatm3rcPv6nx9jxozJ7fIA5BGcAgPwUDl9+rRu3LiR5nNFihRRkSJFHnBFAPIiAhAAALAcToEBAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADL+X+PcH1Xu2hvpgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "39. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy.\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Iris dataset \n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "# convert the iris dataset to a pandas DataFrame\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a range of max_depth values to test\n",
    "max_depth_values = range(1, 21)  # Example: depths from 1 to 20\n",
    "\n",
    "# Store accuracy scores for each max_depth\n",
    "accuracy_scores = []\n",
    "\n",
    "# Train and evaluate for each max_depth\n",
    "for max_depth in max_depth_values:\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=max_depth, random_state=42)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(max_depth_values, accuracy_scores)\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Effect of max_depth on Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3b5c52ad-f7c9-4927-b89e-08c3c291ee2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Estimator: DecisionTreeRegressor\n",
      "Mean Squared Error: 0.2824\n",
      "R-squared: 0.7845\n",
      "--------------------\n",
      "Base Estimator: KNeighborsRegressor\n",
      "Mean Squared Error: 1.0975\n",
      "R-squared: 0.1625\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "40. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare\n",
    "performance.\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.datasets import fetch_california_housing  # Using California housing dataset\n",
    "\n",
    "# Load the California Housing dataset\n",
    "california = fetch_california_housing()\n",
    "X, y = california.data, california.target\n",
    "# convert the california dataset to a pandas DataFrame\n",
    "df = pd.DataFrame(data=california.data, columns=california.feature_names)\n",
    "df['target'] = california.target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define base estimators\n",
    "base_estimators = [\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    KNeighborsRegressor(),\n",
    "]\n",
    "\n",
    "# Train and evaluate each base estimator with bagging\n",
    "for estimator in base_estimators:\n",
    "    bagging_regressor = BaggingRegressor(estimator=estimator, n_estimators=10, random_state=42)\n",
    "    bagging_regressor.fit(X_train, y_train)\n",
    "    y_pred = bagging_regressor.predict(X_test)\n",
    "\n",
    "    # Evaluate performance\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Base Estimator: {estimator.__class__.__name__}\")\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"R-squared: {r2:.4f}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5176d3a8-8203-420b-9146-303ff65a33c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "41. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score.\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.datasets import load_iris  # For example dataset\n",
    "\n",
    "# Load the Iris dataset (you can replace this with your own data)\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "# convert the iris dataset to a pandas DataFrame\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Binarize the target variable for multi-class ROC AUC\n",
    "y_test_binarized = label_binarize(y_test, classes=[0, 1, 2])\n",
    "\n",
    "# Use OneVsRestClassifier for multi-class ROC AUC\n",
    "classifier = OneVsRestClassifier(rf_classifier)\n",
    "y_score = classifier.fit(X_train, y_train).predict_proba(X_test)\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test_binarized, y_score, average='weighted')  # Use 'weighted' for multi-class\n",
    "\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a55ab45d-1b2e-4b92-8471-779edd74cc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1.         0.96666667 0.93333333 1.         0.9       ]\n",
      "Mean accuracy: 0.9600\n",
      "Standard deviation: 0.0389\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "42. Train a Bagging Classifier and evaluate its performance using cross-validation\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier  # Or any other base estimator\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.datasets import load_iris  # For example dataset\n",
    "\n",
    "# Load the Iris dataset (you can replace this with your own data)\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "# convert the iris dataset to a pandas DataFrame\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Create a Bagging Classifier\n",
    "bagging_classifier = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),  # You can change the base estimator\n",
    "    n_estimators=10,  # Number of base estimators (e.g., Decision Trees)\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Define cross-validation strategy (e.g., StratifiedKFold)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold cross-validation\n",
    "\n",
    "# Evaluate performance using cross-validation\n",
    "scores = cross_val_score(bagging_classifier, X, y, cv=cv, scoring='accuracy')  # Use appropriate scoring metric\n",
    "\n",
    "# Print the results\n",
    "print(f\"Cross-validation scores: {scores}\")\n",
    "print(f\"Mean accuracy: {scores.mean():.4f}\")\n",
    "print(f\"Standard deviation: {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c984a853-f631-4d47-b35d-7bb0054ec7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "43. Train a Random Forest Classifier and plot the Precision-Recall curve\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.datasets import load_iris # for example dataset\n",
    "\n",
    "# Load the Iris dataset (you can replace this with your own data)\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "# convert the iris dataset to a pandas DataFrame\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Binarize the target variable for multi-class Precision-Recall curve\n",
    "y_test_binarized = label_binarize(y_test, classes=[0, 1, 2])\n",
    "\n",
    "# Use OneVsRestClassifier for multi-class Precision-Recall curve\n",
    "classifier = OneVsRestClassifier(rf_classifier)\n",
    "y_score = classifier.fit(X_train, y_train).predict_proba(X_test)\n",
    "\n",
    "# Calculate precision and recall for each class\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(len(iris.target_names)):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test_binarized[:, i], y_score[:, i])\n",
    "    average_precision[i] = average_precision_score(y_test_binarized[:, i], y_score[:, i])\n",
    "\n",
    "# Plot the Precision-Recall curve for each class\n",
    "plt.figure()\n",
    "for i, color in zip(range(len(iris.target_names)), ['blue', 'red', 'green']):\n",
    "    plt.plot(recall[i], precision[i], color=color, lw=2,\n",
    "             label='Precision-recall curve of class {0} (area = {1:0.2f})'\n",
    "                   ''.format(iris.target_names[i], average_precision[i]))\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve for Random Forest Classifier')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8f1ba0a-7d36-4131-b6b7-a0ac8e7b5b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy: 1.0\n",
      "rf Accuracy: 1.0\n",
      "lr Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "44. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy.\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris # for example dataset\n",
    "\n",
    "# Load the Iris dataset (you can replace this with your own data)\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "# convert the iris dataset to a pandas DataFrame\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define base estimators\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('lr', LogisticRegression(random_state=42, max_iter=1000)),  # Increased max_iter to avoid convergence warnings\n",
    "]\n",
    "\n",
    "# Define the stacking classifier\n",
    "stacking_classifier = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(random_state=42, max_iter=1000),  # You can change the final estimator\n",
    ")\n",
    "\n",
    "# Train the stacking classifier\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "stacking_predictions = stacking_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "stacking_accuracy = accuracy_score(y_test, stacking_predictions)\n",
    "print(f\"Stacking Classifier Accuracy: {stacking_accuracy}\")\n",
    "\n",
    "# Compare with individual base estimators\n",
    "for name, estimator in estimators:\n",
    "    estimator.fit(X_train, y_train)\n",
    "    predictions = estimator.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"{name} Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f3cf5b5f-6d19-4af6-a4b4-9980cfc5ffb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Sample Size: 0.5\n",
      "Mean Squared Error: 0.3086\n",
      "R-squared: 0.7645\n",
      "--------------------\n",
      "Bootstrap Sample Size: 0.7\n",
      "Mean Squared Error: 0.2913\n",
      "R-squared: 0.7777\n",
      "--------------------\n",
      "Bootstrap Sample Size: 0.9\n",
      "Mean Squared Error: 0.2957\n",
      "R-squared: 0.7743\n",
      "--------------------\n",
      "Bootstrap Sample Size: 1.0\n",
      "Mean Squared Error: 0.2824\n",
      "R-squared: 0.7845\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "45. Train a Bagging Regressor with different levels of bootstrap samples and compare performance.\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor  # Or any other base estimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.datasets import fetch_california_housing  # Using California housing dataset\n",
    "\n",
    "# Load the California Housing dataset\n",
    "california = fetch_california_housing()\n",
    "X, y = california.data, california.target\n",
    "# convert the california dataset to a pandas DataFrame\n",
    "df = pd.DataFrame(data=california.data, columns=california.feature_names)\n",
    "df['target'] = california.target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define bootstrap sample sizes (as proportions of the training data)\n",
    "bootstrap_sizes = [0.5, 0.7, 0.9, 1.0]  # Example: 50%, 70%, 90%, and 100%\n",
    "\n",
    "# Train and evaluate for each bootstrap sample size\n",
    "for bootstrap_size in bootstrap_sizes:\n",
    "    bagging_regressor = BaggingRegressor(\n",
    "        estimator=DecisionTreeRegressor(random_state=42),  # You can change the base estimator\n",
    "        n_estimators=10,\n",
    "        max_samples=bootstrap_size,  # Set bootstrap sample size\n",
    "        random_state=42,\n",
    "    )\n",
    "    bagging_regressor.fit(X_train, y_train)\n",
    "    y_pred = bagging_regressor.predict(X_test)\n",
    "\n",
    "    # Evaluate performance\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Bootstrap Sample Size: {bootstrap_size:.1f}\")\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"R-squared: {r2:.4f}\")\n",
    "    print(\"-\" * 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
